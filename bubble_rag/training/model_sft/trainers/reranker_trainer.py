"""
Reranker model trainer.

Specialized trainer for reranker models using CrossEncoder.
"""

import logging
import os
from typing import Any, Dict, Optional, Union

from sentence_transformers.cross_encoder import CrossEncoder
from sentence_transformers.cross_encoder.losses.BinaryCrossEntropyLoss import BinaryCrossEntropyLoss
from sentence_transformers.cross_encoder.losses.MSELoss import MSELoss
from sentence_transformers.cross_encoder.trainer import CrossEncoderTrainer
from sentence_transformers.cross_encoder.training_args import CrossEncoderTrainingArguments

from ..core.base_trainer import BaseTrainer
from ..utils.evaluation import UnifiedEvaluator

logger = logging.getLogger(__name__)


class RerankerTrainer(BaseTrainer):
    """
    Specialized trainer for reranker models.
    
    Handles CrossEncoder model training with appropriate loss functions
    and training arguments.
    """
    
    def initialize_model(self, model_name: str) -> CrossEncoder:
        """
        Initialize CrossEncoder model.
        
        Args:
            model_name: Name or path of the model
            
        Returns:
            Initialized CrossEncoder model
        """
        logger.info(f"åˆå§‹åŒ– CrossEncoder æ¨¡å‹: {model_name}")
        
        try:
            # Try ModelScope download first (if available)
            try:
                from modelscope import snapshot_download
                from bubble_rag.server_config import TRAINING_CACHE
                
                logger.info(f"å°è¯•ä» ModelScope ä¸‹è½½æ¨¡å‹: {model_name}")
                model_dir = snapshot_download(model_name, cache_dir=TRAINING_CACHE)
                model = CrossEncoder(model_dir)
                logger.info(f"âœ… ModelScope ä¸‹è½½æˆåŠŸï¼Œè·¯å¾„: {model_dir}")
                
            except ImportError:
                logger.info("ModelScope æœªå®‰è£…ï¼Œä½¿ç”¨ HuggingFace æ–¹å¼")
                model = CrossEncoder(model_name)
                logger.info(f"âœ… HuggingFace ä¸‹è½½æˆåŠŸ: {model_name}")
                
            except Exception as e:
                # Fallback to HuggingFace if ModelScope fails
                logger.warning(f"ModelScope ä¸‹è½½å¤±è´¥: {e}ï¼Œå›é€€åˆ° HuggingFace")
                model = CrossEncoder(model_name)
                logger.info(f"âœ… HuggingFace ä¸‹è½½æˆåŠŸ: {model_name}")
            
            # Handle tokenizer pad token
            if model.tokenizer.pad_token is None:
                logger.info("è®¾ç½® tokenizer pad_token")
                model.tokenizer.pad_token = model.tokenizer.eos_token
            
            logger.info(f"CrossEncoder æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_name}")
            return model
            
        except Exception as e:
            # Try offline mode as last resort
            if "couldn't connect" in str(e).lower() or "connection" in str(e).lower():
                logger.warning(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹: {model_name}")
                try:
                    os.environ["TRANSFORMERS_OFFLINE"] = "1"
                    model = CrossEncoder(model_name, local_files_only=True)
                    if model.tokenizer.pad_token is None:
                        model.tokenizer.pad_token = model.tokenizer.eos_token
                    logger.info(f"âœ… æœ¬åœ°ç¼“å­˜åŠ è½½æˆåŠŸ: {model_name}")
                    return model
                except Exception as cache_error:
                    error_msg = f"rerankeræ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {model_name}ï¼Œç½‘ç»œä¸å¯ç”¨ä¸”æœ¬åœ°ç¼“å­˜æœªæ‰¾åˆ°ã€‚é”™è¯¯: {str(cache_error)}"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg)
            else:
                error_msg = f"rerankeræ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {model_name}, é”™è¯¯: {str(e)}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
    
    def create_loss_function(self, model: CrossEncoder, train_dataset: Any) -> Any:
        """
        Create appropriate loss function for reranker training.
        
        Args:
            model: The CrossEncoder model
            train_dataset: Training dataset (can be single dataset or dict of datasets)
            
        Returns:
            Loss function or dict of loss functions for multi-dataset training
        """
        logger.info("åˆ›å»º reranker æŸå¤±å‡½æ•°")
        
        if isinstance(train_dataset, dict):
            # Multi-dataset case: create loss function for each dataset
            losses = {}
            
            for dataset_name, dataset in train_dataset.items():
                # Get target column for this dataset
                target_column = self.evaluator_factory._get_dataset_target_column(dataset)
                
                # Apply column filtering: keep only 2 input columns + target column
                column_names = dataset.column_names
                if len(column_names) >= 3:
                    input_columns = [col for col in column_names if col != target_column][:2]
                    columns_to_keep = input_columns + [target_column]
                    filtered_dataset = dataset.select_columns(columns_to_keep)
                    logger.info(f"Rerankeræ•°æ®é›† '{dataset_name}' åˆ—è¿‡æ»¤: {column_names} â†’ {columns_to_keep}")
                else:
                    filtered_dataset = dataset
                
                # Update the dataset in the training data
                train_dataset[dataset_name] = filtered_dataset
                
                # Create loss function based on target column type
                loss_func = self._create_loss_for_dataset(model, filtered_dataset, target_column, dataset_name)
                losses[dataset_name] = loss_func
            
            logger.info(f"ä¸ºå¤šä¸ªrerankeræ•°æ®é›†åˆ›å»ºäº†æŸå¤±å‡½æ•°: {list(losses.keys())}")
            return losses
        else:
            # Single dataset case
            target_column = self.evaluator_factory._get_dataset_target_column(train_dataset)
            
            # Apply column filtering
            column_names = train_dataset.column_names
            if len(column_names) >= 3:
                input_columns = [col for col in column_names if col != target_column][:2]
                columns_to_keep = input_columns + [target_column]
                train_dataset = train_dataset.select_columns(columns_to_keep)
                logger.info(f"å•Rerankeræ•°æ®é›†åˆ—è¿‡æ»¤: {column_names} â†’ {columns_to_keep}")
            
            # Create single loss function
            loss = self._create_loss_for_dataset(model, train_dataset, target_column)
            logger.info("å•rerankeræ•°æ®é›†æŸå¤±å‡½æ•°åˆ›å»ºå®Œæˆ")
            return loss
    
    def _create_loss_for_dataset(self, model: CrossEncoder, dataset: Any, target_column: str, dataset_name: str = None) -> Any:
        """Create loss function for a specific dataset."""
        try:
            # Check target column data type
            if target_column in dataset.column_names:
                # Sample a few values to determine data type
                sample_values = dataset[target_column][:min(10, len(dataset))]
                
                # Check if all values are integers (classification task)
                is_classification = all(isinstance(val, (int, bool)) or 
                                      (isinstance(val, float) and val.is_integer()) 
                                      for val in sample_values)
                
                if is_classification:
                    loss = BinaryCrossEntropyLoss(model)
                    loss_name = "BinaryCrossEntropyLossï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰"
                else:
                    loss = MSELoss(model)
                    loss_name = "MSELossï¼ˆå›å½’ä»»åŠ¡ï¼‰"
            else:
                # Default to MSE if no target column
                loss = MSELoss(model)
                loss_name = "MSELossï¼ˆé»˜è®¤ï¼‰"
            
            dataset_info = f"æ•°æ®é›† '{dataset_name}'" if dataset_name else "æ•°æ®é›†"
            logger.info(f"ä¸º {dataset_info} åˆ›å»ºæŸå¤±å‡½æ•°: {loss_name}")
            return loss
            
        except Exception as e:
            logger.warning(f"æŸå¤±å‡½æ•°åˆ›å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ MSELoss")
            return MSELoss(model)
    
    def create_training_args(self, config: Dict[str, Any]) -> CrossEncoderTrainingArguments:
        """
        Create CrossEncoderTrainingArguments.

        Args:
            config: Training configuration dictionary (å·²ç»é€šè¿‡base_trainerè¿›è¡Œäº†GPUå…¼å®¹æ€§æ£€æµ‹)

        Returns:
            CrossEncoderTrainingArguments instance
        """
        logger.info("åˆ›å»º CrossEncoderTrainingArguments")

        try:
            args = CrossEncoderTrainingArguments(**config)
            logger.info("CrossEncoderTrainingArguments åˆ›å»ºæˆåŠŸ")
            logger.info(f"ğŸ” [DEBUG] æ··åˆç²¾åº¦è®¾ç½®: bf16={getattr(args, 'bf16', None)}, fp16={getattr(args, 'fp16', None)}")
            return args
        except Exception as e:
            logger.error(f"CrossEncoderTrainingArguments åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def create_trainer_instance(self, model, args, train_dataset, eval_dataset, loss, evaluator) -> CrossEncoderTrainer:
        """
        Create CrossEncoderTrainer instance.
        
        Args:
            model: CrossEncoder model
            args: CrossEncoderTrainingArguments
            train_dataset: Training dataset
            eval_dataset: Evaluation dataset (optional)
            loss: Loss function
            evaluator: Evaluator (optional)
            
        Returns:
            CrossEncoderTrainer instance
        """
        logger.info("åˆ›å»º CrossEncoderTrainer")
        
        # Build trainer arguments
        trainer_kwargs = {
            "model": model,
            "args": args,
            "train_dataset": train_dataset,
            "loss": loss,
        }
        
        # Add evaluation dataset if available
        if eval_dataset is not None:
            # Apply column filtering to evaluation dataset
            if isinstance(eval_dataset, dict):
                # Multi-dataset evaluation
                filtered_eval_dataset = {}
                for dataset_name, dataset in eval_dataset.items():
                    if dataset is not None:
                        target_column = self.evaluator_factory._get_dataset_target_column(dataset)
                        column_names = dataset.column_names
                        if len(column_names) >= 3:
                            input_columns = [col for col in column_names if col != target_column][:2]
                            columns_to_keep = input_columns + [target_column]
                            filtered_eval_dataset[dataset_name] = dataset.select_columns(columns_to_keep)
                            logger.info(f"RerankeréªŒè¯æ•°æ®é›† '{dataset_name}' åˆ—è¿‡æ»¤: {column_names} â†’ {columns_to_keep}")
                        else:
                            filtered_eval_dataset[dataset_name] = dataset
                
                trainer_kwargs["eval_dataset"] = filtered_eval_dataset
            else:
                # Single dataset evaluation
                target_column = self.evaluator_factory._get_dataset_target_column(eval_dataset)
                column_names = eval_dataset.column_names
                if len(column_names) >= 3:
                    input_columns = [col for col in column_names if col != target_column][:2]
                    columns_to_keep = input_columns + [target_column]
                    filtered_eval_dataset = eval_dataset.select_columns(columns_to_keep)
                    logger.info(f"å•éªŒè¯æ•°æ®é›†åˆ—è¿‡æ»¤: {column_names} â†’ {columns_to_keep}")
                else:
                    filtered_eval_dataset = eval_dataset
                
                trainer_kwargs["eval_dataset"] = filtered_eval_dataset
        
        # Add evaluator if available
        if evaluator is not None:
            trainer_kwargs["evaluator"] = evaluator
        
        try:
            trainer = CrossEncoderTrainer(**trainer_kwargs)
            logger.info("CrossEncoderTrainer åˆ›å»ºæˆåŠŸ")
            return trainer
        except Exception as e:
            logger.error(f"CrossEncoderTrainer åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def create_evaluator(self, eval_dataset: Any) -> Optional[Any]:
        """
        Create evaluator for reranker model evaluation.
        
        Args:
            eval_dataset: Evaluation dataset
            
        Returns:
            Evaluator instance or None if no evaluation needed
        """
        logger.info("åˆ›å»º reranker è¯„ä¼°å™¨")
        
        try:
            # Use the unified evaluator factory with correct API
            evaluator = self.evaluator_factory.create_evaluator(
                dataset=eval_dataset,
                target_column="label",  # Default for reranker
                name=f"reranker_evaluator"
            )
            
            if evaluator:
                logger.info("Reranker è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
            else:
                logger.info("æ— éœ€åˆ›å»ºè¯„ä¼°å™¨")
            
            return evaluator
            
        except Exception as e:
            logger.warning(f"è¯„ä¼°å™¨åˆ›å»ºå¤±è´¥: {e}ï¼Œè·³è¿‡è¯„ä¼°")
            return None