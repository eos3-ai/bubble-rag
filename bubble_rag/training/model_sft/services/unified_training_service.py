"""
ç»Ÿä¸€è®­ç»ƒæœåŠ¡å±‚
æä¾›ä¸²è¡Œå’Œå¹¶è¡Œä¸¤ç§è®­ç»ƒæ¨¡å¼ï¼Œæ”¯æŒæœåŠ¡éš”ç¦»å’Œè¿›ç¨‹ç®¡ç†
"""
import os
import threading
import logging
import json
import traceback
import time
import psutil
import multiprocessing as mp
from typing import Optional, Dict, Any, List
from datetime import datetime
from pathlib import Path

from ..models.training_task import TrainingTaskCreateRequest, TrainingTask, TrainingStatus
from ..enums.training_task_enums import ProcessStatus
from .task_manager import task_manager
from bubble_rag.training.mysql_service.service.training_task_service import training_task_service
from .config_service import config_service
from ..utils.gpu_resource_manager import gpu_resource_manager
# from ..utils.gpu_utils import setup_device_environment
from ..utils.service_instance import service_instance_manager
from ..utils.process_manager_base import ProcessManagerBase

logger = logging.getLogger(__name__)

class UnifiedTrainingService(ProcessManagerBase):
    """ç»Ÿä¸€è®­ç»ƒæœåŠ¡ï¼Œæ”¯æŒä¸²è¡Œ(serial)å’Œå¹¶è¡Œ(parallel)ä¸¤ç§æ¨¡å¼"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è®­ç»ƒæœåŠ¡
        
        Args:
            config: æœåŠ¡é…ç½®å­—å…¸
        """
        super().__init__()  # å…ˆè°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.config = config or {}
        
        # é€šè¿‡propertyè®¿é—®service_instance_idï¼ˆä¸æ˜¯ç›´æ¥èµ‹å€¼ï¼‰
        instance_id = self.service_instance_id
        if not instance_id:
            error_msg = "âŒ æœåŠ¡å®ä¾‹IDåˆ›å»ºå¤±è´¥ï¼è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„ TRAINING_SERVER_PORT è®¾ç½®ã€‚"
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        # åˆå§‹åŒ–è®­ç»ƒè¿›ç¨‹ç®¡ç†
        self.training_processes: Dict[str, mp.Process] = {}
        self._lock = threading.RLock()
        self.stop_training_flag = False
        
        # è·å–è®­ç»ƒæ¨¡å¼é…ç½®
        self.default_mode = self.config.get("default_training_mode", "parallel")
        
        logger.info(f"âœ… ç»Ÿä¸€è®­ç»ƒæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ŒæœåŠ¡å®ä¾‹ID: {instance_id}")
        logger.info(f"é»˜è®¤è®­ç»ƒæ¨¡å¼: {self.default_mode}")
        logger.info("ğŸ“ æ³¨æ„ï¼šå­¤å„¿è¿›ç¨‹æ¸…ç†å·²ç”±çˆ¶ç±» ProcessManagerBase._recover_running_processes() å®Œæˆ")
    
    def start_training(self, request: TrainingTaskCreateRequest, training_mode: str = None) -> TrainingTask:
        """
        å¯åŠ¨è®­ç»ƒä»»åŠ¡ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
        
        Args:
            request: è®­ç»ƒä»»åŠ¡åˆ›å»ºè¯·æ±‚
            training_mode: è®­ç»ƒæ¨¡å¼ ("serial" | "parallel")ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„é»˜è®¤æ¨¡å¼
            
        Returns:
            åˆ›å»ºçš„è®­ç»ƒä»»åŠ¡
        """
        # å†æ¬¡æ£€æŸ¥æœåŠ¡å®ä¾‹ID - ç¡®ä¿æœåŠ¡éš”ç¦»
        if not self.service_instance_id:
            error_msg = "âŒ æœåŠ¡å®ä¾‹IDä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºè®­ç»ƒä»»åŠ¡ï¼æœåŠ¡éš”ç¦»å¤±è´¥ã€‚"
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        # ç¡®å®šè®­ç»ƒæ¨¡å¼
        mode = training_mode or self.default_mode
        
        if mode not in ["serial", "parallel"]:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ¨¡å¼: {mode}ï¼Œæ”¯æŒçš„æ¨¡å¼: serial, parallel")
        
        logger.info(f"ğŸš€ å¯åŠ¨è®­ç»ƒä»»åŠ¡ï¼Œæ¨¡å¼: {mode}, æœåŠ¡å®ä¾‹: {self.service_instance_id}")
        
        try:
            # åˆ›å»ºä»»åŠ¡ï¼Œä¼ é€’æœåŠ¡å®ä¾‹ID
            task = task_manager.create_task(request, service_instance_id=self.service_instance_id)
            logger.info(f"åˆ›å»ºè®­ç»ƒä»»åŠ¡æˆåŠŸ: {task.task_id}, æ¨¡å¼: {mode}, æœåŠ¡å®ä¾‹: {self.service_instance_id}")
            
            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¸å…¶ä»–è®­ç»ƒæœåŠ¡ä¿æŒä¸€è‡´ï¼‰
            try:
                # ğŸ” è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ç”¨äºæƒé™æ§åˆ¶
                from bubble_rag.utils.user_manager import UserManager
                current_user = UserManager.validate_and_get_user()
                username = current_user.get('username', 'admin')

                training_task_service.save_training_task(
                    task,
                    request.training_params,
                    service_instance_id=self.service_instance_id,
                    username=username
                )
                logger.info(f"ä»»åŠ¡å·²ä¿å­˜åˆ°æ•°æ®åº“: {task.task_id} (ç”¨æˆ·: {username})")
            except Exception as db_error:
                logger.warning(f"ä¿å­˜ä»»åŠ¡åˆ°æ•°æ®åº“å¤±è´¥ï¼ˆä½†ä»»åŠ¡å·²åˆ›å»ºï¼‰: {str(db_error)}")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ä»»åŠ¡ç»§ç»­æ‰§è¡Œï¼Œåç»­çŠ¶æ€æ›´æ–°æ—¶ä¼šå†æ¬¡å°è¯•ä¿å­˜
            
            # æ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒçš„è®­ç»ƒé€»è¾‘
            if mode == "serial":
                return self._execute_serial_training(task)
            else:  # parallel
                return self._execute_parallel_training(task)
                
        except Exception as e:
            error_msg = f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise RuntimeError(error_msg)
    
    def _execute_serial_training(self, task: TrainingTask) -> TrainingTask:
        """
        æ‰§è¡Œä¸²è¡Œè®­ç»ƒï¼ˆä¸€æ¬¡åªèƒ½è¿è¡Œä¸€ä¸ªä»»åŠ¡ï¼‰
        
        Args:
            task: è®­ç»ƒä»»åŠ¡
            
        Returns:
            è®­ç»ƒä»»åŠ¡
        """
        with self._lock:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            running_tasks = self.get_running_processes()
            if running_tasks:
                running_task_ids = list(running_tasks.keys())
                error_msg = f"ä¸²è¡Œè®­ç»ƒæ¨¡å¼ä¸‹å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ: {running_task_ids}ï¼Œè¯·ç­‰å¾…å®Œæˆåå†å¯åŠ¨æ–°ä»»åŠ¡"
                logger.error(error_msg)
                task_manager.fail_task(task.task_id, error_msg)
                raise RuntimeError(error_msg)
        
        logger.info(f"ğŸ”„ æ‰§è¡Œä¸²è¡Œè®­ç»ƒ: {task.task_id}")
        return self._start_training_process(task, mode="serial")
    
    def _execute_parallel_training(self, task: TrainingTask) -> TrainingTask:
        """
        æ‰§è¡Œå¹¶è¡Œè®­ç»ƒï¼ˆå¯ä»¥åŒæ—¶è¿è¡Œå¤šä¸ªä»»åŠ¡ï¼‰
        
        Args:
            task: è®­ç»ƒä»»åŠ¡
            
        Returns:
            è®­ç»ƒä»»åŠ¡
        """
        logger.info(f"ğŸ”„ æ‰§è¡Œå¹¶è¡Œè®­ç»ƒ: {task.task_id}")
        return self._start_training_process(task, mode="parallel")
    
    def _start_training_process(self, task: TrainingTask, mode: str) -> TrainingTask:
        """
        å¯åŠ¨è®­ç»ƒå­è¿›ç¨‹
        
        Args:
            task: è®­ç»ƒä»»åŠ¡
            mode: è®­ç»ƒæ¨¡å¼
            
        Returns:
            è®­ç»ƒä»»åŠ¡
        """
        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿æœ‰æœåŠ¡å®ä¾‹IDæ‰èƒ½åˆ›å»ºè¿›ç¨‹
        if not self.service_instance_id:
            error_msg = f"âŒ æœåŠ¡å®ä¾‹IDä¸ºç©ºï¼Œæ‹’ç»åˆ›å»ºè®­ç»ƒè¿›ç¨‹ï¼ä»»åŠ¡: {task.task_id}"
            logger.error(error_msg)
            task_manager.fail_task(task.task_id, error_msg)
            raise RuntimeError(error_msg)
        
        try:
            # åˆ†é…GPUèµ„æº
            if mode == "parallel":
                allocated_device = gpu_resource_manager.allocate_gpus_for_task(
                    task.task_id, 
                    task.device
                )
            else:  # serial
                # ä¸²è¡Œæ¨¡å¼ä½¿ç”¨é…ç½®çš„è®¾å¤‡æˆ–auto
                allocated_device = self.config.get("allocated_device") or task.device or "auto"
            
            logger.info(f"ğŸ”§ ä»»åŠ¡ {task.task_id} åˆ†é…è®¾å¤‡: {allocated_device}")
            
            # æ›´æ–°ä»»åŠ¡å¯¹è±¡çš„deviceå­—æ®µä¸ºå®é™…åˆ†é…çš„è®¾å¤‡
            task.device = allocated_device
            task_manager.update_task(task.task_id, {"device": allocated_device})  # æ›´æ–°å†…å­˜ä¸­çš„ä»»åŠ¡
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„deviceå­—æ®µ
            try:
                # ğŸ” è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
                from bubble_rag.utils.user_manager import UserManager
                current_user = UserManager.validate_and_get_user()
                username = current_user.get('username', 'admin')

                training_task_service.save_training_task(
                    task,
                    task.training_params,
                    service_instance_id=self.service_instance_id,
                    username=username
                )
                logger.info(f"ä»»åŠ¡deviceå­—æ®µå·²æ›´æ–°åˆ°æ•°æ®åº“: {task.task_id} -> {allocated_device}")
            except Exception as db_error:
                logger.warning(f"æ›´æ–°ä»»åŠ¡deviceåˆ°æ•°æ®åº“å¤±è´¥: {str(db_error)}")
            
            # æ„å»ºè®­ç»ƒé…ç½®å­—å…¸ï¼ˆç»“æ„åŒ–å‚æ•°ä¼ é€’ï¼‰
            training_config = dict(task.training_params)
            
            # æ·»åŠ ä»»åŠ¡æ ¸å¿ƒä¿¡æ¯åˆ°training_config
            training_config.update({
                "task_id": task.task_id,
                "train_type": task.train_type,
                "model_name_or_path": task.model_name_or_path,
                "dataset_name_or_path": task.dataset_name_or_path,
                "output_dir": task.output_dir,
                "device": allocated_device
                # æ³¨æ„ï¼štraining_mode ä¸åº”è¯¥åŠ å…¥ training_configï¼Œå®ƒæ˜¯æœåŠ¡å±‚æ§åˆ¶å‚æ•°
            })
            
            logger.info(f"ä¼ é€’è®­ç»ƒé…ç½®å‚æ•°: {list(training_config.keys())}")
            
            # åˆ›å»ºè¿›ç¨‹å‚æ•°
            process_args = {
                'task_id': task.task_id,
                'service_instance_id': self.service_instance_id,
                'allocated_device': allocated_device,
                'training_config': training_config,
                'task_config': task.model_dump(),  # ä½¿ç”¨ model_dump() è€Œä¸æ˜¯ dict()
                'training_mode': mode
            }
            
            # å¯åŠ¨multiprocessing.Process
            process = mp.Process(
                target=UnifiedTrainingService._run_training_in_process,
                args=(process_args,),
                name=f"{mode}-training-{task.task_id[:8]}"
            )
            
            process.start()
            
            # è®°å½•è¿›ç¨‹ä¿¡æ¯åˆ°æ•°æ®åº“
            try:
                from ..enums import ProcessStatus
                success = training_task_service.update_process_info(
                    task.task_id, 
                    process_pid=process.pid,
                    process_status=ProcessStatus.RUNNING.value,
                    service_instance_id=self.service_instance_id
                )
                if success:
                    logger.info(f"âœ… è®°å½•è¿›ç¨‹ä¿¡æ¯åˆ°æ•°æ®åº“æˆåŠŸ: ä»»åŠ¡={task.task_id}, PID={process.pid}, çŠ¶æ€=RUNNING, æ¨¡å¼={mode}")
                else:
                    logger.error(f"âŒ è®°å½•è¿›ç¨‹ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥: update_process_infoè¿”å›False")
            except Exception as e:
                logger.error(f"âŒ è®°å½•è¿›ç¨‹ä¿¡æ¯å¼‚å¸¸: {str(e)}", exc_info=True)
            
            # ğŸ”§ åŒæ­¥è¿›ç¨‹PIDåˆ°ä»»åŠ¡ç®¡ç†å™¨çš„å†…å­˜ä»»åŠ¡å¯¹è±¡
            try:
                task.process_pid = process.pid
                task_manager._save_tasks()  # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
                logger.info(f"âœ… å·²åŒæ­¥PIDåˆ°ä»»åŠ¡ç®¡ç†å™¨: {task.task_id} -> PID={process.pid}")
            except Exception as e:
                logger.warning(f"åŒæ­¥PIDåˆ°ä»»åŠ¡ç®¡ç†å™¨å¤±è´¥: {str(e)}")
            
            # ä¿å­˜è¿›ç¨‹å¼•ç”¨
            with self._lock:
                self.training_processes[task.task_id] = process
                self.process_info[task.task_id] = {
                    'pid': process.pid,
                    'started_at': datetime.now(),
                    'status': ProcessStatus.RUNNING.value,
                    'mode': mode,
                    'service_instance_id': self.service_instance_id
                }
            
            # è¿›ç¨‹å·²å¯åŠ¨æˆåŠŸï¼Œä¿æŒPENDINGçŠ¶æ€ï¼Œç­‰å¾…çœŸæ­£å¼€å§‹è®­ç»ƒæ—¶å†æ›´æ–°ä¸ºRUNNING
            try:
                # ä¸è°ƒç”¨start_taskï¼Œè®©ä»»åŠ¡ä¿æŒPENDINGçŠ¶æ€ï¼Œç­‰å¾…å­è¿›ç¨‹çœŸæ­£å¼€å§‹è®­ç»ƒæ—¶æ‰æ›´æ–°ä¸ºRUNNING
                training_task_service.update_task_status(task.task_id, TrainingStatus.PENDING.value)
                logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ: {task.task_id} (PENDING - ç­‰å¾…è®­ç»ƒå¼€å§‹)")
            except Exception as status_error:
                logger.warning(f"ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼ˆä½†è¿›ç¨‹å·²å¯åŠ¨ï¼‰: {str(status_error)}")
            
            logger.info(f"âœ… è®­ç»ƒä»»åŠ¡å·²å¯åŠ¨: {task.task_id}, æ¨¡å¼: {mode}, PID: {process.pid}")
            return task
            
        except Exception as e:
            error_msg = f"å¯åŠ¨è®­ç»ƒè¿›ç¨‹å¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            
            # åªæœ‰åœ¨è¿›ç¨‹å¯åŠ¨å‰å¤±è´¥æ—¶æ‰æ ‡è®°ä»»åŠ¡å¤±è´¥
            try:
                task_manager.fail_task(task.task_id, error_msg, traceback.format_exc())
            except Exception as db_error:
                logger.warning(f"æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€å¤±è´¥: {str(db_error)}")
            
            # é‡Šæ”¾èµ„æº
            if mode == "parallel":
                gpu_resource_manager.release_gpus_for_task(task.task_id)
            
            raise RuntimeError(error_msg)
    
    @staticmethod
    def _run_training_in_process(process_args: dict):
        """
        åœ¨å­è¿›ç¨‹ä¸­æ‰§è¡Œè®­ç»ƒçš„å®é™…é€»è¾‘
        
        Args:
            process_args: è¿›ç¨‹å‚æ•°å­—å…¸
        """
        try:
            # æå–å‚æ•°
            task_id = process_args['task_id']
            service_instance_id = process_args['service_instance_id']
            allocated_device = process_args['allocated_device']
            training_config = process_args['training_config']
            task_config = process_args['task_config']
            training_mode = process_args['training_mode']
            
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œè®­ç»ƒä»»åŠ¡: {task_id} (æ¨¡å¼: {training_mode})")
            logger.info(f"ğŸ“¦ æœåŠ¡å®ä¾‹ID: {service_instance_id}")
            logger.info(f"ğŸ”§ åˆ†é…è®¾å¤‡: {allocated_device}")
            
            # è®¾ç½®è®¾å¤‡ç¯å¢ƒå˜é‡ï¼ˆå­è¿›ç¨‹ç¯å¢ƒéš”ç¦»ï¼‰
            if allocated_device and allocated_device != "auto":
                os.environ["CUDA_VISIBLE_DEVICES"] = allocated_device.replace("cuda:", "")
                logger.info(f"ğŸ”§ è®¾ç½®CUDAè®¾å¤‡: {os.environ['CUDA_VISIBLE_DEVICES']}")
            
            # åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(current_step: int, total_steps: int, stage: str = "training"):
                """è¿›åº¦å›è°ƒå‡½æ•°"""
                try:
                    # æ£€æµ‹å¼‚å¸¸çš„total_stepså€¼ï¼ˆä¿ç•™ä½œä¸ºå®‰å…¨æ£€æŸ¥ï¼‰
                    if total_steps <= 0:
                        logger.warning(f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸çš„total_steps: {total_steps}, è·³è¿‡è¿›åº¦æ›´æ–°")
                        return

                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼Œä½†é˜²æ­¢è¿‡æ—©è®¾ç½®100%
                    if total_steps > 0:
                        raw_progress = (current_step / total_steps) * 100.0

                        # ğŸ”§ é˜²æ­¢åœ¨è®­ç»ƒå®Œæˆå‰è®¾ç½®100%è¿›åº¦ï¼šå°†99.5%ä»¥ä¸Šçš„è¿›åº¦é™åˆ¶ä¸º99.5%
                        # åªæœ‰å½“è®­ç»ƒçœŸæ­£å®Œæˆæ—¶ï¼Œæ‰ä¼šåœ¨completion handlerä¸­è®¾ç½®100%
                        progress = min(raw_progress, 99.5) if stage.lower() in ["training", "è®­ç»ƒä¸­"] else raw_progress
                    else:
                        progress = 0.0
                    
                    message = f"{stage}: {current_step}/{total_steps}"
                    
                    # æ›´æ–°ä»»åŠ¡ç®¡ç†å™¨
                    from ..services.task_manager import task_manager
                    task_manager.update_task_progress(task_id, progress, message)
                    
                    # ğŸ”§ é¿å…ç›´æ¥æ›´æ–°æ•°æ®åº“ï¼Œä½¿ç”¨task_managerçš„1%èŠ‚æµæœºåˆ¶
                    # è¿™æ ·å¯ä»¥é¿å…é¢‘ç¹çš„æ•°æ®åº“æ›´æ–°ï¼Œå¹¶ä¸”è¿›åº¦æ›´æ–°é€»è¾‘æ›´ç»Ÿä¸€
                    
                    logger.info(f"è®­ç»ƒè¿›åº¦ {progress:.1f}%: {message}")
                except Exception as e:
                    logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
            
            # å¯¼å…¥é‡æ„åçš„è®­ç»ƒå‡½æ•°
            from ..train import main

            # æ‰§è¡Œè®­ç»ƒï¼ˆçŠ¶æ€æ›´æ–°å°†åœ¨è®­ç»ƒå¾ªç¯çœŸæ­£å¼€å§‹æ—¶è¿›è¡Œï¼‰
            model, save_dir = main(
                progress_callback=progress_callback,
                training_config=training_config
            )
            
            logger.info(f"âœ… è®­ç»ƒå®Œæˆ: {task_id}")
            logger.info(f"ğŸ“ æ¨¡å‹ä¿å­˜è·¯å¾„: {save_dir}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            from ..services.task_manager import task_manager
            from bubble_rag.training.mysql_service.service.training_task_service import training_task_service
            
            # ğŸ”§ å…ˆæ›´æ–°ä»»åŠ¡ç®¡ç†å™¨ï¼ˆè¿™ä¼šè®¾ç½®çŠ¶æ€ä¸ºSUCCEEDEDå’Œè¿›åº¦100%ï¼‰
            task_manager.complete_task(task_id, save_dir)
            
            # ğŸ”§ å†æ›´æ–°æ•°æ®åº“ï¼ˆæ­¤æ—¶task_manager.update_task_progressä¼šå…è®¸100%è¿›åº¦å†™å…¥ï¼‰
            task_manager.update_task_progress(task_id, 100.0, "è®­ç»ƒå®Œæˆ")
            
            # ğŸ”§ æ›´æ–°æ•°æ®åº“ä»»åŠ¡çŠ¶æ€ä¸ºSUCCEEDED
            from bubble_rag.training.model_sft.enums.training_task_enums import TrainingStatus
            training_task_service.update_task_status(task_id, TrainingStatus.SUCCEEDED.value)
            training_task_service.update_task_result(task_id, final_model_path=save_dir)
            logger.info(f"âœ… æ•°æ®åº“ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸ºSUCCEEDED: {task_id}")
            
            # ğŸ”§ è®­ç»ƒæˆåŠŸå®Œæˆåé‡Šæ”¾GPUèµ„æº
            try:
                from ..utils.gpu_resource_manager import gpu_resource_manager
                success = gpu_resource_manager.release_gpus_for_task(task_id)
                if success:
                    logger.info(f"âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼Œå·²é‡Šæ”¾ä»»åŠ¡ {task_id} çš„GPUèµ„æº")
                else:
                    logger.warning(f"å¸¸è§„GPUé‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡Šæ”¾")
                    gpu_resource_manager.force_release_gpu_for_task(task_id)

                # å¢å¼ºGPUæ¸…ç†ï¼ˆé™æ€æ–¹æ³•ä¸­ä¸èƒ½ä½¿ç”¨selfï¼Œç›´æ¥è°ƒç”¨GPUèµ„æºç®¡ç†å™¨ï¼‰
                logger.info("GPUèµ„æºå·²é€šè¿‡gpu_resource_manageré‡Šæ”¾")
            except Exception as gpu_error:
                logger.critical(f"âŒ ä¸¥é‡é”™è¯¯ï¼šè®­ç»ƒå®ŒæˆåGPUèµ„æºé‡Šæ”¾å¤±è´¥ï¼å°è¯•å¼ºåˆ¶æ¢å¤ã€‚ä»»åŠ¡: {task_id}, é”™è¯¯: {gpu_error}")
                try:
                    gpu_resource_manager.force_release_gpu_for_task(task_id)
                    logger.warning(f"ğŸ”§ å¼ºåˆ¶GPUé‡Šæ”¾å·²æ‰§è¡Œ")
                except Exception as force_error:
                    logger.critical(f"âŒ å¼ºåˆ¶GPUé‡Šæ”¾ä¹Ÿå¤±è´¥ï¼ä»»åŠ¡ {task_id} èµ„æºå¯èƒ½æ°¸ä¹…æ³„æ¼: {force_error}")
            
        except Exception as e:
            error_msg = f"è®­ç»ƒæ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            
            # æ›´æ–°å¤±è´¥çŠ¶æ€
            try:
                from ..services.task_manager import task_manager
                from bubble_rag.training.mysql_service.service.training_task_service import training_task_service
                from bubble_rag.training.model_sft.enums import TrainingStatus

                task_manager.fail_task(task_id, error_msg, traceback.format_exc())
                training_task_service.update_task_status(task_id, TrainingStatus.FAILED.value)
                training_task_service.update_task_result(task_id, error_message=error_msg)

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šè®­ç»ƒå¤±è´¥æ—¶ä¹Ÿè¦é‡Šæ”¾GPUèµ„æº
                try:
                    from ..utils.gpu_resource_manager import gpu_resource_manager
                    success = gpu_resource_manager.release_gpus_for_task(task_id)
                    if success:
                        logger.info(f"ğŸ”“ è®­ç»ƒå¤±è´¥ï¼Œå·²é‡Šæ”¾ä»»åŠ¡ {task_id} çš„GPUèµ„æº")
                    else:
                        logger.warning(f"å¸¸è§„GPUé‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡Šæ”¾")
                        gpu_resource_manager.force_release_gpu_for_task(task_id)
                except Exception as gpu_error:
                    logger.error(f"âŒ è®­ç»ƒå¤±è´¥æ—¶é‡Šæ”¾GPUèµ„æºå¤±è´¥: {gpu_error}")
                    try:
                        gpu_resource_manager.force_release_gpu_for_task(task_id)
                        logger.warning(f"ğŸ”§ å¼ºåˆ¶GPUé‡Šæ”¾å·²æ‰§è¡Œ")
                    except Exception as force_error:
                        logger.critical(f"âŒ å¼ºåˆ¶GPUé‡Šæ”¾ä¹Ÿå¤±è´¥ï¼ä»»åŠ¡ {task_id} èµ„æºå¯èƒ½æ°¸ä¹…æ³„æ¼: {force_error}")

            except Exception as update_error:
                logger.error(f"æ›´æ–°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {update_error}")
            
            # æŠ›å‡ºå¼‚å¸¸ä»¥è®¾ç½®è¿›ç¨‹é€€å‡ºç 
            raise
        finally:
            # æ— è®ºä»€ä¹ˆæ¨¡å¼éƒ½é‡Šæ”¾GPUèµ„æºï¼ˆä½œä¸ºæœ€ç»ˆä¿é™©ï¼‰
            try:
                from ..utils.gpu_resource_manager import gpu_resource_manager
                success = gpu_resource_manager.release_gpus_for_task(task_id)
                if success:
                    logger.info(f"ğŸ”§ Finallyå—ï¼šç¡®ä¿é‡Šæ”¾ä»»åŠ¡ {task_id} çš„GPUèµ„æº")
                else:
                    logger.warning(f"Finallyå—ï¼šå¸¸è§„GPUé‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡Šæ”¾")
                    gpu_resource_manager.force_release_gpu_for_task(task_id)

                # å¢å¼ºGPUæ¸…ç†ï¼ˆæœ€ç»ˆä¿é™©ï¼‰- é™æ€æ–¹æ³•ä¸­ä¸èƒ½ä½¿ç”¨self
                logger.info("Finallyå—ï¼šGPUèµ„æºå·²é€šè¿‡gpu_resource_manageré‡Šæ”¾")
            except Exception as e:
                logger.critical(f"âŒ ä¸¥é‡é”™è¯¯ï¼šFinallyå—GPUèµ„æºé‡Šæ”¾å¤±è´¥ï¼å°è¯•å¼ºåˆ¶æ¢å¤ã€‚ä»»åŠ¡: {task_id}, é”™è¯¯: {e}")
                try:
                    gpu_resource_manager.force_release_gpu_for_task(task_id)
                    logger.warning(f"ğŸ”§ å¼ºåˆ¶GPUé‡Šæ”¾å·²æ‰§è¡Œ")
                except Exception as force_error:
                    logger.critical(f"âŒ å¼ºåˆ¶GPUé‡Šæ”¾ä¹Ÿå¤±è´¥ï¼ä»»åŠ¡ {task_id} èµ„æºå¯èƒ½æ°¸ä¹…æ³„æ¼: {force_error}")
    
    def stop_training(self, task_id: str) -> bool:
        """
        åœæ­¢æŒ‡å®šçš„è®­ç»ƒä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸåœæ­¢
        """
        try:
            with self._lock:
                process = self.training_processes.get(task_id)
                if not process:
                    logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id} çš„è¿›ç¨‹")
                    # ğŸ”§ å¢å¼ºåœæ­¢æœºåˆ¶ï¼šé€šè¿‡æ•°æ®åº“æŸ¥è¯¢PIDå¹¶å°è¯•åœæ­¢
                    return self._stop_training_by_database(task_id)
                
                if not process.is_alive():
                    logger.info(f"ä»»åŠ¡ {task_id} è¿›ç¨‹å·²ç»“æŸï¼Œä»éœ€æ¸…ç†GPUèµ„æº")
                    self.training_processes.pop(task_id, None)

                    # ğŸ”§ å³ä½¿è¿›ç¨‹å·²ç»“æŸï¼Œä¹Ÿè¦æ¸…ç†GPUèµ„æº
                    task_manager.cancel_task(task_id)
                    training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)

                    # æ¸…ç†GPUèµ„æº
                    success = self._enhanced_gpu_cleanup(task_id)
                    if not success:
                        logger.warning(f"è¿›ç¨‹å·²ç»“æŸä½†GPUæ¸…ç†å¤±è´¥: {task_id}")

                    return True
                
                # ğŸŒ³ ä½¿ç”¨ç»Ÿä¸€çš„è¿›ç¨‹æ ‘ç»ˆæ­¢æ–¹æ³•
                pid = process.pid
                logger.info(f"ğŸŒ³ ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•ç»ˆæ­¢è®­ç»ƒè¿›ç¨‹æ ‘ (ä»»åŠ¡: {task_id}, PID: {pid})")
                
                # å…ˆä½¿ç”¨ç»Ÿä¸€çš„è¿›ç¨‹æ ‘æ¸…ç†æ–¹æ³•
                success = self._terminate_process_tree_by_pid(pid)
                
                if not success:
                    # å¦‚æœç»Ÿä¸€æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°åŸæ¥çš„multiprocessingæ–¹å¼
                    logger.warning(f"ç»Ÿä¸€æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°multiprocessingç»ˆæ­¢æ–¹å¼")
                    try:
                        process.terminate()
                        process.join(timeout=30)
                        logger.info(f"âœ… è®­ç»ƒè¿›ç¨‹å·²é€šè¿‡multiprocessingç»ˆæ­¢")
                    except:
                        logger.warning(f"è¿›ç¨‹ç»ˆæ­¢è¶…æ—¶ï¼Œä½¿ç”¨å¼ºåˆ¶ç»ˆæ­¢")
                    process.kill()
                    process.join()
                    logger.info(f"ğŸ’€ è®­ç»ƒè¿›ç¨‹å·²å¼ºåˆ¶ç»ˆæ­¢")
                
                # æ¸…ç†è¿›ç¨‹å¼•ç”¨
                self.training_processes.pop(task_id, None)
                if task_id in self.process_info:
                    from ..enums.training_task_enums import ProcessStatus
                    self.process_info[task_id]['status'] = ProcessStatus.STOPPED.value
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task_manager.cancel_task(task_id)
                training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)
                
                # ğŸ”§ æ›´æ–°æ•°æ®åº“ä¸­çš„è¿›ç¨‹çŠ¶æ€
                try:
                    from ..enums.training_task_enums import ProcessStatus
                    # è·å–å½“å‰ä»»åŠ¡çš„PIDä¿¡æ¯
                    current_task = task_manager.get_task(task_id)
                    current_pid = current_task.process_pid if current_task else None
                    
                    training_task_service.update_process_info(
                        task_id=task_id,
                        process_pid=current_pid,  # ğŸ”§ ä¿ç•™PIDç”¨äºå®¡è®¡è¿½è¸ª
                        process_status=ProcessStatus.STOPPED.value
                    )
                    logger.info(f"âœ… å·²æ›´æ–°è¿›ç¨‹çŠ¶æ€ä¸ºSTOPPED: {task_id} (ä¿ç•™PID: {current_pid})")
                except Exception as update_error:
                    logger.warning(f"æ›´æ–°è¿›ç¨‹çŠ¶æ€å¤±è´¥: {update_error}")
                
                # ğŸ”§ å¢å¼ºGPUèµ„æºæ¸…ç†
                success = self._enhanced_gpu_cleanup(task_id)
                if not success:
                    logger.warning(f"å¢å¼ºGPUæ¸…ç†å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥GPUçŠ¶æ€")

                logger.info(f"âœ… å·²åœæ­¢è®­ç»ƒä»»åŠ¡: {task_id}")
                return True
                
        except Exception as e:
            logger.error(f"åœæ­¢è®­ç»ƒä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
            return False
    
    def _stop_training_by_database(self, task_id: str) -> bool:
        """
        é€šè¿‡æ•°æ®åº“ä¸­çš„PIDåœæ­¢è®­ç»ƒä»»åŠ¡ï¼ˆå›é€€æœºåˆ¶ï¼‰
        å½“å†…å­˜ä¸­çš„è¿›ç¨‹å¼•ç”¨ä¸¢å¤±æ—¶ä½¿ç”¨
        """
        import psutil
        
        try:
            # ä»æ•°æ®åº“è·å–ä»»åŠ¡ä¿¡æ¯
            task_db = training_task_service.get_training_task(task_id)
            if not task_db:
                logger.error(f"æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰PIDè®°å½•
            if not task_db.process_pid:
                logger.warning(f"ä»»åŠ¡ {task_id} æ²¡æœ‰PIDè®°å½•ï¼Œç›´æ¥æ¸…ç†çŠ¶æ€å’ŒGPUèµ„æº")
                # ç›´æ¥æ›´æ–°çŠ¶æ€ä¸ºåœæ­¢
                task_manager.cancel_task(task_id)
                training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)
                # ğŸ”§ æ›´æ–°è¿›ç¨‹çŠ¶æ€
                from ..enums.training_task_enums import ProcessStatus
                training_task_service.update_process_info(task_id, None, ProcessStatus.STOPPED.value)

                # ğŸ”§ æ¸…ç†GPUèµ„æº
                success = self._enhanced_gpu_cleanup(task_id)
                if not success:
                    logger.warning(f"æ— PIDä»»åŠ¡GPUæ¸…ç†å¤±è´¥: {task_id}")

                return True
            
            pid = task_db.process_pid
            logger.info(f"ğŸ”§ å°è¯•é€šè¿‡PID {pid} åœæ­¢è®­ç»ƒä»»åŠ¡ {task_id}")
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
            if not psutil.pid_exists(pid):
                logger.info(f"è¿›ç¨‹ {pid} å·²ä¸å­˜åœ¨ï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€å¹¶æ¸…ç†GPUèµ„æº")
                task_manager.cancel_task(task_id)
                training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)
                # ğŸ”§ æ›´æ–°è¿›ç¨‹çŠ¶æ€
                from ..enums.training_task_enums import ProcessStatus
                training_task_service.update_process_info(task_id, None, ProcessStatus.STOPPED.value)

                # ğŸ”§ æ¸…ç†GPUèµ„æº
                success = self._enhanced_gpu_cleanup(task_id)
                if not success:
                    logger.warning(f"å·²ç»“æŸè¿›ç¨‹GPUæ¸…ç†å¤±è´¥: {task_id}")

                return True
            
            # è·å–è¿›ç¨‹å¯¹è±¡å¹¶åœæ­¢
            try:
                process = psutil.Process(pid)
                process_name = process.name()
                
                # éªŒè¯è¿™ç¡®å®æ˜¯æˆ‘ä»¬çš„è®­ç»ƒè¿›ç¨‹
                if 'python' not in process_name.lower():
                    logger.warning(f"PID {pid} ä¸æ˜¯Pythonè¿›ç¨‹: {process_name}")
                    return False
                
                # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„è¿›ç¨‹æ ‘ç»ˆæ­¢æ–¹æ³•
                logger.info(f"ğŸ›‘ æ£€æµ‹åˆ°è®­ç»ƒè¿›ç¨‹ {pid} ({process_name})")
                logger.info(f"ğŸŒ³ ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•ç»ˆæ­¢è¿›ç¨‹æ ‘ï¼ˆåŒ…æ‹¬æ‰€æœ‰å­è¿›ç¨‹ï¼‰")
                
                # è°ƒç”¨ç»Ÿä¸€çš„è¿›ç¨‹æ ‘æ¸…ç†æ–¹æ³•
                success = self._terminate_process_tree_by_pid(pid)
                
                # æ— è®ºè¿›ç¨‹ç»ˆæ­¢æˆåŠŸä¸å¦ï¼Œéƒ½è¦æ›´æ–°çŠ¶æ€å’Œæ¸…ç†èµ„æº
                # æ›´æ–°çŠ¶æ€
                task_manager.cancel_task(task_id)
                training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)
                # ğŸ”§ æ›´æ–°è¿›ç¨‹çŠ¶æ€
                from ..enums.training_task_enums import ProcessStatus
                training_task_service.update_process_info(task_id, None, ProcessStatus.STOPPED.value)
                
                # ğŸ”§ å¢å¼ºGPUèµ„æºæ¸…ç†
                gpu_success = self._enhanced_gpu_cleanup(task_id)
                if not gpu_success:
                    logger.warning(f"å¢å¼ºGPUæ¸…ç†å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥GPUçŠ¶æ€")

                if success:
                    logger.info(f"âœ… è¿›ç¨‹æ ‘å·²é€šè¿‡ç»Ÿä¸€æ–¹æ³•æˆåŠŸç»ˆæ­¢: PID {pid}")
                    return True
                else:
                    logger.warning(f"âš ï¸ ç»Ÿä¸€æ–¹æ³•å¤±è´¥ï¼Œä½†ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: PID {pid}")
                    return False
                
            except psutil.NoSuchProcess:
                logger.info(f"è¿›ç¨‹ {pid} å·²ç»“æŸï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€å¹¶æ¸…ç†GPUèµ„æº")
                task_manager.cancel_task(task_id)
                training_task_service.update_task_status(task_id, TrainingStatus.STOPPED.value)
                # ğŸ”§ æ›´æ–°è¿›ç¨‹çŠ¶æ€
                from ..enums.training_task_enums import ProcessStatus
                training_task_service.update_process_info(task_id, None, ProcessStatus.STOPPED.value)

                # ğŸ”§ æ¸…ç†GPUèµ„æº
                success = self._enhanced_gpu_cleanup(task_id)
                if not success:
                    logger.warning(f"NoSuchProcesså¼‚å¸¸GPUæ¸…ç†å¤±è´¥: {task_id}")

                return True
            except psutil.AccessDenied:
                logger.error(f"æ— æƒé™è®¿é—®è¿›ç¨‹ {pid}")
                return False
                
        except Exception as e:
            logger.error(f"é€šè¿‡æ•°æ®åº“PIDåœæ­¢è®­ç»ƒå¤±è´¥: {str(e)}", exc_info=True)
            return False

    def get_running_processes(self) -> Dict[str, Dict]:
        """
        è·å–æ­£åœ¨è¿è¡Œçš„è®­ç»ƒè¿›ç¨‹
        
        Returns:
            æ­£åœ¨è¿è¡Œçš„è¿›ç¨‹ä¿¡æ¯å­—å…¸
        """
        with self._lock:
            running = {}
            for task_id, process in list(self.training_processes.items()):
                if process.is_alive():
                    running[task_id] = {
                        'pid': process.pid,
                        'process_info': self.process_info.get(task_id, {}),
                        'process': process
                    }
                else:
                    # æ¸…ç†å·²ç»“æŸçš„è¿›ç¨‹
                    self.training_processes.pop(task_id, None)
                    if task_id in self.process_info:
                        from ..enums.training_task_enums import ProcessStatus
                        self.process_info[task_id]['status'] = ProcessStatus.STOPPED.value

                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ¸…ç†è¿›ç¨‹æ—¶åŒæ—¶é‡Šæ”¾GPUèµ„æº
                    try:
                        from ..utils.gpu_resource_manager import gpu_resource_manager
                        if gpu_resource_manager.release_gpus_for_task(task_id):
                            logger.info(f"âœ… è¿›ç¨‹æ¸…ç†æ—¶é‡Šæ”¾ä»»åŠ¡ {task_id} çš„GPUèµ„æº")
                        else:
                            logger.warning(f"âš ï¸ è¿›ç¨‹æ¸…ç†æ—¶GPUé‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡Šæ”¾: {task_id}")
                            gpu_resource_manager.force_release_gpu_for_task(task_id)
                    except Exception as gpu_e:
                        logger.error(f"âŒ è¿›ç¨‹æ¸…ç†æ—¶GPUèµ„æºé‡Šæ”¾å¤±è´¥: {task_id}, é”™è¯¯: {gpu_e}")
            
            return running
    
    def get_training_status(self, task_id: str) -> Optional[Dict]:
        """
        è·å–è®­ç»ƒçŠ¶æ€ï¼ˆå®ç°æŠ½è±¡æ–¹æ³•ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            è®­ç»ƒçŠ¶æ€ä¿¡æ¯
        """
        try:
            # ä»ä»»åŠ¡ç®¡ç†å™¨è·å–ä»»åŠ¡ä¿¡æ¯
            task = task_manager.get_task(task_id)
            if not task:
                return None
            
            # è·å–è¿›ç¨‹ä¿¡æ¯
            with self._lock:
                process = self.training_processes.get(task_id)
                process_info = self.process_info.get(task_id, {})
            
            return {
                "task_info": task.get_summary(),
                "process_alive": process.is_alive() if process else False,
                "process_info": process_info,
                "service_instance_id": self.service_instance_id
            }
            
        except Exception as e:
            logger.error(f"è·å–è®­ç»ƒçŠ¶æ€å¤±è´¥: {str(e)}")
            return None
    
    def cleanup_completed_processes(self):
        """æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹å¹¶æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
        with self._lock:
            completed_tasks = []
            for task_id, process in list(self.training_processes.items()):
                if not process.is_alive():
                    completed_tasks.append(task_id)
                    process.join()  # ç¡®ä¿è¿›ç¨‹èµ„æºè¢«é‡Šæ”¾
                    
            for task_id in completed_tasks:
                self.training_processes.pop(task_id, None)
                if task_id in self.process_info:
                    self.process_info[task_id]['status'] = 'COMPLETED'
                
                # ğŸ”§ è¿›ç¨‹ç›‘æ§æ£€æµ‹åˆ°è®­ç»ƒå®Œæˆï¼Œæ¸…ç†GPUèµ„æº
                try:
                    from ..utils.gpu_resource_manager import gpu_resource_manager
                    gpu_resource_manager.release_gpus_for_task(task_id)
                    logger.info(f"ğŸ” è¿›ç¨‹ç›‘æ§ï¼šæ£€æµ‹åˆ°ä»»åŠ¡ {task_id} å®Œæˆï¼Œå·²é‡Šæ”¾GPUèµ„æº")
                    
                    # å¢å¼ºGPUæ¸…ç†
                    gpu_success = self._enhanced_gpu_cleanup(task_id)
                    if not gpu_success:
                        logger.warning(f"è¿›ç¨‹ç›‘æ§ï¼šå¢å¼ºGPUæ¸…ç†å¤±è´¥")
                except Exception as gpu_error:
                    logger.error(f"âŒ è¿›ç¨‹ç›‘æ§GPUæ¸…ç†å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶æ¢å¤ã€‚ä»»åŠ¡: {task_id}, é”™è¯¯: {gpu_error}")
                    try:
                        gpu_resource_manager.force_release_gpu_for_task(task_id)
                        logger.warning(f"ğŸ”§ å¼ºåˆ¶GPUé‡Šæ”¾å·²æ‰§è¡Œ")
                    except Exception as force_error:
                        logger.critical(f"âŒ å¼ºåˆ¶GPUé‡Šæ”¾ä¹Ÿå¤±è´¥ï¼ä»»åŠ¡ {task_id} èµ„æºå¯èƒ½æ°¸ä¹…æ³„æ¼: {force_error}")
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„è¿›ç¨‹çŠ¶æ€
                try:
                    from ..enums import ProcessStatus
                    # è·å–å½“å‰ä»»åŠ¡çš„PIDä¿¡æ¯
                    current_task = task_manager.get_task(task_id)
                    current_pid = current_task.process_pid if current_task else None
                    
                    training_task_service.update_process_info(
                        task_id=task_id,
                        process_pid=current_pid,  # ğŸ”§ ä¿ç•™PIDç”¨äºå®¡è®¡è¿½è¸ª
                        process_status=ProcessStatus.STOPPED.value
                    )
                    logger.info(f"âœ… æ›´æ–°æ•°æ®åº“è¿›ç¨‹çŠ¶æ€: ä»»åŠ¡={task_id}, çŠ¶æ€=STOPPED (ä¿ç•™PID: {current_pid})")
                except Exception as e:
                    logger.warning(f"æ›´æ–°è¿›ç¨‹çŠ¶æ€å¤±è´¥: ä»»åŠ¡={task_id}, é”™è¯¯={e}")
                    
            if completed_tasks:
                logger.info(f"æ¸…ç†äº† {len(completed_tasks)} ä¸ªå·²å®Œæˆçš„è¿›ç¨‹: {completed_tasks}")


    # å®ç°æŠ½è±¡åŸºç±»çš„å¿…éœ€æ–¹æ³•
    def start_training_process(self, task) -> bool:
        """å¯åŠ¨è®­ç»ƒè¿›ç¨‹ - æŠ½è±¡æ–¹æ³•å®ç°"""
        try:
            # è¿™é‡Œç›´æ¥è°ƒç”¨å†…éƒ¨çš„è®­ç»ƒå¯åŠ¨æ–¹æ³•
            result_task = self._start_training_process(task, self.default_mode)
            return result_task is not None
        except Exception as e:
            logger.error(f"å¯åŠ¨è®­ç»ƒè¿›ç¨‹å¤±è´¥: {e}")
            return False

    def stop_training_process(self, task_id: str) -> bool:
        """åœæ­¢è®­ç»ƒè¿›ç¨‹ - æŠ½è±¡æ–¹æ³•å®ç°"""
        return self.stop_training(task_id)

    def check_unknown_processes(self) -> Dict[str, Any]:
        """æ£€æŸ¥å’Œæ¢å¤UNKNOWNçŠ¶æ€è¿›ç¨‹ - ä»£ç†åˆ°è¿›ç¨‹ç®¡ç†å™¨"""
        try:
            # ä»£ç†åˆ°ProcessManagerBaseçš„check_unknown_processesæ–¹æ³•
            return super().check_unknown_processes()
        except Exception as e:
            logger.error(f"æ£€æŸ¥UNKNOWNçŠ¶æ€è¿›ç¨‹å¤±è´¥: {str(e)}")
            return {'error': str(e), 'total_unknown': 0, 'recovered_running': 0, 'recovered_terminated': 0, 'still_unknown': 0, 'error_count': 1}

    def delete_task(self, task_id: str) -> tuple[bool, str]:
        """
        åˆ é™¤è®­ç»ƒä»»åŠ¡
        
        åŠŸèƒ½ï¼š
        1. å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å¹¶æ€æ­»è¿›ç¨‹
        2. æ›´æ–°ä»»åŠ¡å’Œè¿›ç¨‹çŠ¶æ€
        3. ä»å†…å­˜å’Œæ•°æ®åº“ä¸­åˆ é™¤ä»»åŠ¡è®°å½•
        
        è¿”å›ï¼š
        - (success: bool, message: str)
        """
        try:
            from bubble_rag.training.mysql_service.service.training_task_service import training_task_service
            from bubble_rag.training.model_sft.services.task_manager import task_manager
            
            logger.info(f"ğŸ—‘ï¸ å¼€å§‹åˆ é™¤ä»»åŠ¡: {task_id}")
            
            # 1. æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
            task_db = training_task_service.get_training_task(task_id)
            if not task_db:
                return False, f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"
            
            # 2. æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Œå¦‚æœæ˜¯åˆ™å…ˆåœæ­¢
            memory_task = task_manager.get_task(task_id)
            is_running = task_id in self.processes
            
            if is_running or (memory_task and memory_task.status == "RUNNING"):
                logger.info(f"ğŸ›‘ ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢: {task_id}")
                
                # åœæ­¢è®­ç»ƒä»»åŠ¡å’Œè¿›ç¨‹
                stop_success = self.stop_training(task_id)
                if not stop_success:
                    logger.warning(f"åœæ­¢ä»»åŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­åˆ é™¤æµç¨‹: {task_id}")
                
                # å¼ºåˆ¶æ€æ­»è¿›ç¨‹ï¼ˆå¦‚æœè¿˜åœ¨è¿è¡Œï¼‰
                if task_id in self.processes:
                    try:
                        process_info = self.processes[task_id]
                        pid = process_info.get("pid")
                        if pid:
                            import psutil
                            try:
                                process = psutil.Process(pid)
                                # ğŸŒ³ ä½¿ç”¨ç»Ÿä¸€çš„è¿›ç¨‹æ ‘ç»ˆæ­¢æ–¹æ³•ï¼ˆåˆ é™¤ä»»åŠ¡æ—¶ä¹Ÿè¦å½»åº•æ¸…ç†ï¼‰
                                logger.info(f"ğŸ”« åˆ é™¤ä»»åŠ¡ï¼šä½¿ç”¨è¿›ç¨‹æ ‘æ¸…ç†æ–¹æ³• PID={pid}")
                                success = self._terminate_process_tree_by_pid(pid)
                                if success:
                                    logger.info(f"âœ… è¿›ç¨‹æ ‘æ¸…ç†æˆåŠŸ: PID={pid}")
                                else:
                                    logger.warning(f"âš ï¸ è¿›ç¨‹æ ‘æ¸…ç†å¤±è´¥ï¼Œä½†ç»§ç»­åˆ é™¤æµç¨‹: PID={pid}")

                                # ğŸ”§ å…³é”®ä¿®å¤ï¼šåˆ é™¤ä»»åŠ¡æ—¶ä¹Ÿè¦ç¡®ä¿GPUèµ„æºé‡Šæ”¾
                                logger.info(f"ğŸ”§ åˆ é™¤ä»»åŠ¡ï¼šå¼ºåˆ¶æ¸…ç†GPUèµ„æº {task_id}")
                                gpu_success = self._enhanced_gpu_cleanup(task_id)
                                if not gpu_success:
                                    logger.warning(f"åˆ é™¤ä»»åŠ¡æ—¶GPUæ¸…ç†å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥GPUçŠ¶æ€")

                            except psutil.NoSuchProcess:
                                logger.info(f"è¿›ç¨‹å·²ä¸å­˜åœ¨: PID={pid}")
                                # è¿›ç¨‹ä¸å­˜åœ¨æ—¶ä¹Ÿè¦æ¸…ç†GPUèµ„æº
                                logger.info(f"ğŸ”§ è¿›ç¨‹å·²ä¸å­˜åœ¨ï¼Œæ¸…ç†GPUèµ„æº {task_id}")
                                self._enhanced_gpu_cleanup(task_id)
                            except Exception as e:
                                logger.warning(f"æ€æ­»è¿›ç¨‹å¤±è´¥: PID={pid}, é”™è¯¯={e}")
                                # è¿›ç¨‹æ¸…ç†å¤±è´¥æ—¶ä¹Ÿè¦å°è¯•æ¸…ç†GPUèµ„æº
                                logger.info(f"ğŸ”§ è¿›ç¨‹æ¸…ç†å¤±è´¥ï¼Œå¼ºåˆ¶æ¸…ç†GPUèµ„æº {task_id}")
                                self._enhanced_gpu_cleanup(task_id)
                    except Exception as e:
                        logger.warning(f"å¤„ç†è¿è¡Œè¿›ç¨‹å¤±è´¥: {e}")
                        # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè¦å°è¯•æ¸…ç†GPUèµ„æº
                        logger.info(f"ğŸ”§ å¼‚å¸¸æƒ…å†µï¼Œå¼ºåˆ¶æ¸…ç†GPUèµ„æº {task_id}")
                        try:
                            self._enhanced_gpu_cleanup(task_id)
                        except Exception as gpu_error:
                            logger.error(f"å¼‚å¸¸æƒ…å†µä¸‹GPUæ¸…ç†å¤±è´¥: {gpu_error}")

                    # ä»è¿è¡Œè¿›ç¨‹åˆ—è¡¨ä¸­ç§»é™¤
                    self.processes.pop(task_id, None)

            # ğŸ”§ é¢å¤–ä¿é™©ï¼šé€šè¿‡è¿›ç¨‹åæŸ¥æ‰¾å¹¶æ¸…ç†å¯èƒ½é—æ¼çš„è¿›ç¨‹
            logger.info(f"ğŸ”§ åˆ é™¤ä»»åŠ¡ï¼šé€šè¿‡è¿›ç¨‹åæ£€æŸ¥é—æ¼çš„è®­ç»ƒè¿›ç¨‹ {task_id}")
            try:
                self._cleanup_processes_by_name(task_id)
            except Exception as cleanup_error:
                logger.warning(f"é€šè¿‡è¿›ç¨‹åæ¸…ç†å¤±è´¥: {cleanup_error}")

            # ğŸ”§ é¢å¤–ä¿é™©ï¼šæ— è®ºå‰é¢çš„æ¸…ç†æ˜¯å¦æˆåŠŸï¼Œéƒ½å†æ¬¡å°è¯•GPUæ¸…ç†
            logger.info(f"ğŸ”§ åˆ é™¤ä»»åŠ¡æœ€ç»ˆä¿é™©ï¼šç¡®ä¿GPUèµ„æºæ¸…ç† {task_id}")
            try:
                final_gpu_success = self._enhanced_gpu_cleanup(task_id)
                if final_gpu_success:
                    logger.info(f"âœ… åˆ é™¤ä»»åŠ¡GPUæ¸…ç†æœ€ç»ˆç¡®è®¤æˆåŠŸ: {task_id}")
                else:
                    logger.warning(f"âš ï¸ åˆ é™¤ä»»åŠ¡GPUæ¸…ç†æœ€ç»ˆç¡®è®¤å¤±è´¥: {task_id}")
            except Exception as final_gpu_error:
                logger.error(f"åˆ é™¤ä»»åŠ¡GPUæ¸…ç†æœ€ç»ˆç¡®è®¤å¼‚å¸¸: {final_gpu_error}")
            
            # 3. ä»å†…å­˜ä¸­åˆ é™¤ä»»åŠ¡
            if memory_task:
                logger.info(f"ğŸ§  ä»å†…å­˜åˆ é™¤ä»»åŠ¡: {task_id}")
                task_manager.delete_task(task_id)
            
            # 4. æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡å’Œè¿›ç¨‹çŠ¶æ€ä¸ºå·²ç»ˆæ­¢
            logger.info(f"ğŸ“Š æ›´æ–°æ•°æ®åº“çŠ¶æ€: {task_id}")
            
            # å¯¼å…¥ProcessStatusæšä¸¾
            from ..enums.training_task_enums import ProcessStatus
            from ..enums import TrainingStatus
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
            training_task_service.update_task_status(
                task_id=task_id,
                status=TrainingStatus.STOPPED.value
            )
            training_task_service.update_task_result(
                task_id=task_id,
                error_message="ä»»åŠ¡å·²åˆ é™¤"
            )
            
            # æ›´æ–°è¿›ç¨‹çŠ¶æ€
            training_task_service.update_process_info(
                task_id=task_id,
                process_pid=None,  # ä»»åŠ¡åˆ é™¤æ—¶æ¸…ç©ºPID
                process_status=ProcessStatus.TERMINATED.value
            )
            
            # 5. åˆ é™¤å…³è”çš„æ•°æ®é›†è®°å½•
            logger.info(f"ğŸ—‚ï¸ åˆ é™¤å…³è”æ•°æ®é›†: {task_id}")
            dataset_deleted_count = 0
            dataset_message = ""
            try:
                from bubble_rag.training.mysql_service.service.training_dataset_service import training_dataset_service
                dataset_deleted_count, dataset_message = training_dataset_service.delete_datasets_by_task(task_id)
                logger.info(f"ğŸ“Š æ•°æ®é›†åˆ é™¤ç»“æœ: {dataset_message}")
            except Exception as e:
                logger.warning(f"åˆ é™¤æ•°æ®é›†å¤±è´¥ï¼Œä½†ç»§ç»­åˆ é™¤ä»»åŠ¡: {e}")
                dataset_message = f"æ•°æ®é›†åˆ é™¤å¤±è´¥: {str(e)}"

            # 6. ä»æ•°æ®åº“ä¸­åˆ é™¤ä»»åŠ¡è®°å½•
            logger.info(f"ğŸ—„ï¸ ä»æ•°æ®åº“åˆ é™¤ä»»åŠ¡è®°å½•: {task_id}")
            db_success = training_task_service.delete_training_task(task_id)

            if db_success:
                dataset_info = f"ï¼ŒåŒæ—¶åˆ é™¤äº† {dataset_deleted_count} ä¸ªæ•°æ®é›†è®°å½•" if dataset_deleted_count > 0 else ""
                logger.info(f"âœ… ä»»åŠ¡åˆ é™¤æˆåŠŸ: {task_id}{dataset_info}")
                return True, f"ä»»åŠ¡ {task_id} å·²æˆåŠŸåˆ é™¤{dataset_info}"
            else:
                logger.error(f"âŒ æ•°æ®åº“åˆ é™¤å¤±è´¥: {task_id}")
                return False, "ä»æ•°æ®åº“åˆ é™¤ä»»åŠ¡å¤±è´¥"
                
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}", exc_info=True)
            return False, f"åˆ é™¤ä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"

    def _terminate_process_tree_by_pid(self, pid: int) -> bool:
        """ç»Ÿä¸€çš„è¿›ç¨‹æ ‘ç»ˆæ­¢æ–¹æ³• - é€‚ç”¨äºæ‰€æœ‰åœºæ™¯ï¼ˆæ‰‹åŠ¨åœæ­¢ã€æœåŠ¡é‡å¯ç­‰ï¼‰"""
        try:
            import psutil
            logger.info(f"ğŸŒ³ å¼€å§‹ç»ˆæ­¢è¿›ç¨‹æ ‘ PID={pid}")
            
            # è·å–ä¸»è¿›ç¨‹
            try:
                process = psutil.Process(pid)
            except psutil.NoSuchProcess:
                logger.info(f"è¿›ç¨‹ {pid} å·²ä¸å­˜åœ¨")
                return True
            
            # 1. è·å–æ‰€æœ‰å­è¿›ç¨‹
            children = []
            try:
                children = process.children(recursive=True)
                logger.info(f"ğŸ” å‘ç° {len(children)} ä¸ªå­è¿›ç¨‹éœ€è¦ç»ˆæ­¢")
                for child in children:
                    try:
                        logger.info(f"   å­è¿›ç¨‹: PID {child.pid}, åç§°: {child.name()}")
                    except:
                        logger.info(f"   å­è¿›ç¨‹: PID {child.pid}, åç§°: è·å–å¤±è´¥")
            except psutil.NoSuchProcess:
                logger.warning(f"ä¸»è¿›ç¨‹ {pid} å·²ä¸å­˜åœ¨")
                return True
            except Exception as e:
                logger.warning(f"è·å–å­è¿›ç¨‹å¤±è´¥: {e}")
            
            # 2. å…ˆç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹ï¼ˆdataloader workersç­‰ï¼‰
            for child in children:
                try:
                    child.terminate()
                    logger.info(f"ğŸ”¥ å·²ç»ˆæ­¢å­è¿›ç¨‹: PID {child.pid}")
                except psutil.NoSuchProcess:
                    logger.info(f"å­è¿›ç¨‹ {child.pid} å·²ä¸å­˜åœ¨")
                except Exception as e:
                    logger.warning(f"ç»ˆæ­¢å­è¿›ç¨‹ {child.pid} å¤±è´¥: {e}")
            
            # 3. ç­‰å¾…å­è¿›ç¨‹ä¼˜é›…é€€å‡º
            import time
            time.sleep(1)
            
            # 4. å¼ºåˆ¶ç»ˆæ­¢ä»ç„¶å­˜æ´»çš„å­è¿›ç¨‹
            for child in children:
                try:
                    if child.is_running():
                        child.kill()
                        logger.warning(f"ğŸ’€ å¼ºåˆ¶ç»ˆæ­¢é¡½å›ºå­è¿›ç¨‹: PID {child.pid}")
                except psutil.NoSuchProcess:
                    pass
                except Exception as e:
                    logger.error(f"å¼ºåˆ¶ç»ˆæ­¢å­è¿›ç¨‹ {child.pid} å¤±è´¥: {e}")
            
            # 5. ç»ˆæ­¢ä¸»è¿›ç¨‹
            try:
                process.terminate()
                logger.info(f"ğŸ”¥ å·²ç»ˆæ­¢ä¸»è¿›ç¨‹: PID {pid}")
                
                # ç­‰å¾…ä¸»è¿›ç¨‹ä¼˜é›…é€€å‡º
                try:
                    process.wait(timeout=5)
                    logger.info(f"âœ… ä¸»è¿›ç¨‹å·²ä¼˜é›…ç»ˆæ­¢: PID {pid}")
                except psutil.TimeoutExpired:
                    # å¼ºåˆ¶æ€æ­»ä¸»è¿›ç¨‹
                    process.kill()
                    logger.info(f"ğŸ’¥ ä¸»è¿›ç¨‹å·²å¼ºåˆ¶ç»ˆæ­¢: PID {pid}")
                    
            except psutil.NoSuchProcess:
                logger.info(f"ä¸»è¿›ç¨‹ {pid} å·²ä¸å­˜åœ¨")
            except Exception as e:
                logger.error(f"ç»ˆæ­¢ä¸»è¿›ç¨‹ {pid} å¤±è´¥: {e}")
                return False
                
            logger.info(f"âœ… è¿›ç¨‹æ ‘ç»ˆæ­¢å®Œæˆ: PID {pid}")
            return True
            
        except Exception as e:
            logger.error(f"ç»ˆæ­¢è¿›ç¨‹æ ‘å¤±è´¥ PID={pid}: {e}")
            return False

    def _enhanced_gpu_cleanup(self, task_id: str) -> bool:
        """
        å¢å¼ºGPUèµ„æºæ¸…ç†æœºåˆ¶
        ä¸ä»…é‡Šæ”¾GPUèµ„æºç®¡ç†å™¨ä¸­çš„åˆ†é…ï¼Œè¿˜æ¸…ç†å¯èƒ½æ®‹ç•™çš„GPUå†…å­˜

        Returns:
            bool: True if successful, False if failed
        """
        success = True
        try:
            # 1. é‡Šæ”¾GPUèµ„æºç®¡ç†å™¨åˆ†é…
            release_success = gpu_resource_manager.release_gpus_for_task(task_id)
            if release_success:
                logger.info(f"ğŸ”§ å·²é‡Šæ”¾GPUèµ„æºç®¡ç†å™¨ä¸­çš„ä»»åŠ¡ {task_id} èµ„æº")
            else:
                logger.warning(f"GPUèµ„æºç®¡ç†å™¨é‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡Šæ”¾")
                success = gpu_resource_manager.force_release_gpu_for_task(task_id)
        except Exception as e:
            logger.error(f"âŒ GPUèµ„æºç®¡ç†å™¨èµ„æºé‡Šæ”¾å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶æ¢å¤ã€‚é”™è¯¯: {e}")
            try:
                success = gpu_resource_manager.force_release_gpu_for_task(task_id)
                logger.warning(f"ğŸ”§ å¼ºåˆ¶GPUé‡Šæ”¾å·²æ‰§è¡Œ")
            except Exception as force_error:
                logger.critical(f"âŒ å¼ºåˆ¶GPUé‡Šæ”¾ä¹Ÿå¤±è´¥ï¼ä»»åŠ¡ {task_id} èµ„æºå¯èƒ½æ°¸ä¹…æ³„æ¼: {force_error}")
                success = False
        
        try:
            # 2. å¼ºåˆ¶æ¸…ç†CUDAå†…å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            import torch
            if torch.cuda.is_available():
                # æ¸…ç©ºCUDAç¼“å­˜
                torch.cuda.empty_cache()
                logger.info(f"ğŸ§¹ å·²æ¸…ç©ºCUDAå†…å­˜ç¼“å­˜")
                
                # è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                for i in range(torch.cuda.device_count()):
                    memory_allocated = torch.cuda.memory_allocated(i)
                    memory_cached = torch.cuda.memory_reserved(i)
                    if memory_allocated > 0 or memory_cached > 0:
                        logger.info(f"GPU {i}: å·²åˆ†é…={memory_allocated/1024/1024:.1f}MB, ç¼“å­˜={memory_cached/1024/1024:.1f}MB")
                        # å°è¯•è¿›ä¸€æ­¥æ¸…ç†
                        try:
                            torch.cuda.empty_cache()
                            torch.cuda.ipc_collect()
                        except:
                            pass
        except ImportError:
            # PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡CUDAæ¸…ç†
            pass
        except Exception as e:
            logger.warning(f"æ¸…ç†CUDAå†…å­˜å¤±è´¥: {e}")
        
        try:
            # 3. ç³»ç»Ÿçº§GPUè¿›ç¨‹æ¸…ç†ï¼ˆå¯é€‰ï¼Œç”¨äºæç«¯æƒ…å†µï¼‰
            import subprocess
            import platform
            
            # å°è¯•æŸ¥æ‰¾å¯èƒ½çš„æ®‹ç•™GPUè¿›ç¨‹
            if platform.system() == "Linux":
                try:
                    # ä½¿ç”¨nvidia-smiæŸ¥çœ‹GPUè¿›ç¨‹
                    result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,process_name', '--format=csv,noheader'], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and result.stdout:
                        gpu_processes = result.stdout.strip().split('\n')
                        logger.info(f"ğŸ” å½“å‰GPUè¿›ç¨‹: {len(gpu_processes)}ä¸ª")
                        for proc in gpu_processes:
                            if proc.strip():
                                logger.info(f"   GPUè¿›ç¨‹: {proc}")
                except subprocess.TimeoutExpired:
                    logger.warning("nvidia-smiæŸ¥è¯¢è¶…æ—¶")
                except Exception as e:
                    logger.debug(f"nvidia-smiæŸ¥è¯¢å¤±è´¥: {e}")
        except Exception as e:
            logger.debug(f"ç³»ç»Ÿçº§GPUæ£€æŸ¥å¤±è´¥: {e}")
        
        logger.info(f"âœ… GPUèµ„æºæ¸…ç†å®Œæˆ: ä»»åŠ¡ {task_id}")
        return success

    def _cleanup_processes_by_name(self, task_id: str) -> bool:
        """
        é€šè¿‡è¿›ç¨‹åå’Œå‘½ä»¤è¡ŒæŸ¥æ‰¾å¹¶æ¸…ç†å¯èƒ½é—æ¼çš„è®­ç»ƒè¿›ç¨‹
        è¿™æ˜¯ä¸€ä¸ªè¡¥å……æ¸…ç†æœºåˆ¶ï¼Œç”¨äºæ•è·PID-basedæ¸…ç†å¯èƒ½é—æ¼çš„è¿›ç¨‹

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            bool: True if successful cleanup, False if issues found
        """
        try:
            import psutil
            import re
            import os

            logger.info(f"ğŸ” å¼€å§‹æŒ‰è¿›ç¨‹åæ¸…ç†é—æ¼çš„è®­ç»ƒè¿›ç¨‹: {task_id}")

            # å®šä¹‰å¯èƒ½çš„è®­ç»ƒè¿›ç¨‹åç§°æ¨¡å¼
            training_patterns = [
                r'python.*train.*',
                r'.*accelerate.*',
                r'.*torch.*distributed.*',
                r'.*deepspeed.*',
                r'.*transformers.*',
                r'.*train_model.*',
                r'.*sft_training.*'
            ]

            # æœç´¢åŒ…å«task_idçš„è¿›ç¨‹
            task_id_patterns = [
                task_id,  # ç›´æ¥åŒ¹é…task_id
                f'task_id.*{task_id}',  # å‘½ä»¤è¡Œå‚æ•°åŒ…å«task_id
                f'{task_id}.*train',  # task_idåœ¨è®­ç»ƒå‘½ä»¤ä¸­
            ]

            found_processes = []
            terminated_count = 0

            # éå†æ‰€æœ‰è¿›ç¨‹
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):
                try:
                    proc_info = proc.info
                    pid = proc_info['pid']
                    name = proc_info['name'] or ''
                    cmdline = ' '.join(proc_info['cmdline'] or [])

                    # è·³è¿‡ç³»ç»Ÿè¿›ç¨‹å’Œå½“å‰Pythonè¿›ç¨‹
                    if pid <= 1 or pid == os.getpid():
                        continue

                    # æ£€æŸ¥æ˜¯å¦æ˜¯è®­ç»ƒç›¸å…³è¿›ç¨‹
                    is_training_process = False
                    for pattern in training_patterns:
                        if re.search(pattern, name, re.IGNORECASE) or re.search(pattern, cmdline, re.IGNORECASE):
                            is_training_process = True
                            break

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«task_id
                    contains_task_id = False
                    for pattern in task_id_patterns:
                        if re.search(pattern, cmdline, re.IGNORECASE):
                            contains_task_id = True
                            break

                    # å¦‚æœæ˜¯è®­ç»ƒè¿›ç¨‹ä¸”åŒ…å«task_idï¼Œåˆ™éœ€è¦æ¸…ç†
                    if is_training_process and contains_task_id:
                        found_processes.append({
                            'pid': pid,
                            'name': name,
                            'cmdline': cmdline[:200],  # é™åˆ¶é•¿åº¦
                            'create_time': proc_info['create_time']
                        })

                        logger.warning(f"ğŸ¯ å‘ç°é—æ¼çš„è®­ç»ƒè¿›ç¨‹: PID={pid}, åç§°={name}")
                        logger.info(f"   å‘½ä»¤è¡Œ: {cmdline[:100]}...")

                        # å°è¯•ç»ˆæ­¢è¿™ä¸ªè¿›ç¨‹
                        try:
                            process = psutil.Process(pid)
                            process.terminate()
                            logger.info(f"ğŸ”¥ å·²ç»ˆæ­¢é—æ¼è¿›ç¨‹: PID={pid}")

                            # ç­‰å¾…è¿›ç¨‹é€€å‡º
                            try:
                                process.wait(timeout=3)
                                logger.info(f"âœ… é—æ¼è¿›ç¨‹å·²ä¼˜é›…ç»ˆæ­¢: PID={pid}")
                                terminated_count += 1
                            except psutil.TimeoutExpired:
                                # å¼ºåˆ¶æ€æ­»
                                try:
                                    process.kill()
                                    logger.warning(f"ğŸ’€ å¼ºåˆ¶ç»ˆæ­¢é—æ¼è¿›ç¨‹: PID={pid}")
                                    terminated_count += 1
                                except:
                                    logger.error(f"å¼ºåˆ¶ç»ˆæ­¢é—æ¼è¿›ç¨‹å¤±è´¥: PID={pid}")

                        except psutil.NoSuchProcess:
                            logger.info(f"é—æ¼è¿›ç¨‹å·²ä¸å­˜åœ¨: PID={pid}")
                            terminated_count += 1
                        except Exception as e:
                            logger.error(f"ç»ˆæ­¢é—æ¼è¿›ç¨‹å¤±è´¥: PID={pid}, é”™è¯¯={e}")

                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    # è¿›ç¨‹å¯èƒ½å·²ç»æ¶ˆå¤±æˆ–æ— æƒé™è®¿é—®ï¼Œè·³è¿‡
                    continue
                except Exception as e:
                    logger.debug(f"æ£€æŸ¥è¿›ç¨‹å¤±è´¥: {e}")
                    continue

            if found_processes:
                logger.warning(f"âš ï¸ å‘ç° {len(found_processes)} ä¸ªé—æ¼çš„è®­ç»ƒè¿›ç¨‹ï¼Œå·²ç»ˆæ­¢ {terminated_count} ä¸ª")
                return terminated_count == len(found_processes)
            else:
                logger.info(f"âœ… æœªå‘ç°é—æ¼çš„è®­ç»ƒè¿›ç¨‹: {task_id}")
                return True

        except Exception as e:
            logger.error(f"æŒ‰è¿›ç¨‹åæ¸…ç†å¤±è´¥: {task_id}, é”™è¯¯: {e}")
            return False

# å…¨å±€ç»Ÿä¸€è®­ç»ƒæœåŠ¡å®ä¾‹
unified_training_service = UnifiedTrainingService()