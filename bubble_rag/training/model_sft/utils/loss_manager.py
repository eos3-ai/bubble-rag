"""
è®­ç»ƒLossæœ¬åœ°æ–‡ä»¶ç®¡ç†å™¨
è´Ÿè´£å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„lossæ•°æ®ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…æ•°æ®åº“æ€§èƒ½é—®é¢˜
"""

import json
import os
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from threading import Lock

logger = logging.getLogger(__name__)


class LossManager:
    """è®­ç»ƒLossæœ¬åœ°æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, output_dir: str, task_id: str):
        """
        åˆå§‹åŒ–Lossç®¡ç†å™¨
        
        Args:
            output_dir: è®­ç»ƒè¾“å‡ºç›®å½•
            task_id: è®­ç»ƒä»»åŠ¡ID
        """
        self.output_dir = output_dir
        self.task_id = task_id
        self.lock = Lock()
        
        # è®¾ç½®æ—¥å¿—ç›®å½•ç»“æ„: {output_dir}/logs/training/{task_id}/
        self.logs_dir = Path(output_dir) / "logs" / "training" / task_id
        self.loss_history_file = self.logs_dir / "loss_history.jsonl"
        self.training_metrics_file = self.logs_dir / "training_metrics.json"
        
        # åˆ›å»ºç›®å½•
        self._ensure_directories()
        
        # åˆå§‹åŒ–è®­ç»ƒæŒ‡æ ‡
        self.training_metrics = {
            "task_id": task_id,
            "start_time": datetime.now().isoformat(),
            "total_steps": 0,
            "epochs_completed": 0,
            "best_train_loss": None,
            "best_eval_loss": None,
            "loss_records_count": 0,
            "last_updated": None,
            "epoch_summaries": [],  # æ¯ä¸ªepochçš„æ±‡æ€»ä¿¡æ¯
            "final_results": {}     # æœ€ç»ˆè¯„ä¼°ç»“æœ
        }
        
        logger.info(f"âœ… Lossç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {self.logs_dir}")
    
    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•ç»“æ„å­˜åœ¨"""
        try:
            self.logs_dir.mkdir(parents=True, exist_ok=True)
            logger.debug(f"ğŸ“ åˆ›å»ºæ—¥å¿—ç›®å½•: {self.logs_dir}")
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ—¥å¿—ç›®å½•å¤±è´¥: {e}")
            raise
    
    def save_loss_record(self, step: int, metrics: Dict[str, Any], epoch: Optional[float] = None):
        """
        ä¿å­˜å•æ¬¡lossè®°å½•åˆ°JSONLæ–‡ä»¶
        
        Args:
            step: è®­ç»ƒæ­¥æ•°
            metrics: æŒ‡æ ‡å­—å…¸ï¼ˆåŒ…å«train_loss, eval_lossç­‰ï¼‰
            epoch: å½“å‰epochï¼ˆå¯é€‰ï¼‰
        """
        with self.lock:
            try:
                # æ„å»ºè®°å½•
                record = {
                    "step": step,
                    "timestamp": datetime.now().isoformat(),
                    **metrics
                }
                
                if epoch is not None:
                    record["epoch"] = epoch
                
                # å†™å…¥JSONLæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªJSONï¼‰
                with open(self.loss_history_file, 'a', encoding='utf-8') as f:
                    json.dump(record, f, ensure_ascii=False)
                    f.write('\n')
                
                # æ›´æ–°è®­ç»ƒæŒ‡æ ‡
                self._update_training_metrics(step, metrics, epoch)
                
                logger.debug(f"ğŸ“Š ä¿å­˜lossè®°å½•: step={step}, metrics={list(metrics.keys())}")
                
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜lossè®°å½•å¤±è´¥: {e}")
    
    def _update_training_metrics(self, step: int, metrics: Dict[str, Any], epoch: Optional[float]):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡æ±‡æ€»"""
        try:
            # æ›´æ–°åŸºç¡€ä¿¡æ¯
            self.training_metrics["total_steps"] = max(self.training_metrics["total_steps"], step)
            self.training_metrics["loss_records_count"] += 1
            self.training_metrics["last_updated"] = datetime.now().isoformat()
            
            if epoch is not None:
                self.training_metrics["epochs_completed"] = max(
                    self.training_metrics["epochs_completed"], epoch
                )
            
            # æ›´æ–°æœ€ä½³loss
            if "train_loss" in metrics:
                train_loss = metrics["train_loss"]
                if (self.training_metrics["best_train_loss"] is None or 
                    train_loss < self.training_metrics["best_train_loss"]):
                    self.training_metrics["best_train_loss"] = train_loss
            
            if "eval_loss" in metrics:
                eval_loss = metrics["eval_loss"]
                if (self.training_metrics["best_eval_loss"] is None or 
                    eval_loss < self.training_metrics["best_eval_loss"]):
                    self.training_metrics["best_eval_loss"] = eval_loss
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self.training_metrics_file, 'w', encoding='utf-8') as f:
                json.dump(self.training_metrics, f, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")
    
    def finalize_epoch(self, epoch: int, epoch_metrics: Dict[str, Any]):
        """
        å®Œæˆä¸€ä¸ªepochï¼Œä¿å­˜epochæ±‡æ€»ä¿¡æ¯
        
        Args:
            epoch: epochç¼–å·
            epoch_metrics: epochæ±‡æ€»æŒ‡æ ‡
        """
        with self.lock:
            try:
                epoch_summary = {
                    "epoch": epoch,
                    "timestamp": datetime.now().isoformat(),
                    **epoch_metrics
                }
                
                # æ·»åŠ åˆ°epochæ±‡æ€»åˆ—è¡¨
                self.training_metrics["epoch_summaries"].append(epoch_summary)
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(self.training_metrics_file, 'w', encoding='utf-8') as f:
                    json.dump(self.training_metrics, f, ensure_ascii=False, indent=2)
                
                logger.info(f"ğŸ“Š Epoch {epoch} æ±‡æ€»å·²ä¿å­˜: {list(epoch_metrics.keys())}")
                
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜epochæ±‡æ€»å¤±è´¥: {e}")
    
    def get_loss_history(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–losså†å²è®°å½•
        
        Args:
            limit: é™åˆ¶è¿”å›çš„è®°å½•æ•°é‡
            
        Returns:
            lossè®°å½•åˆ—è¡¨
        """
        try:
            if not self.loss_history_file.exists():
                return []
            
            records = []
            with open(self.loss_history_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        records.append(json.loads(line.strip()))
            
            # åº”ç”¨é™åˆ¶
            if limit and len(records) > limit:
                records = records[-limit:]  # è¿”å›æœ€è¿‘çš„è®°å½•
            
            return records
            
        except Exception as e:
            logger.error(f"âŒ è·å–losså†å²å¤±è´¥: {e}")
            return []
    
    def get_training_metrics(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæŒ‡æ ‡æ±‡æ€»"""
        try:
            if self.training_metrics_file.exists():
                with open(self.training_metrics_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return self.training_metrics
        except Exception as e:
            logger.error(f"âŒ è·å–è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")
            return self.training_metrics
    
    def get_database_summary(self) -> Dict[str, Any]:
        """
        è·å–ç”¨äºæ•°æ®åº“å­˜å‚¨çš„æ±‡æ€»ä¿¡æ¯
        
        Returns:
            æ•°æ®åº“æ±‡æ€»ä¿¡æ¯å­—å…¸
        """
        try:
            summary = {
                "task_id": self.task_id,
                "loss_file_path": str(self.loss_history_file),
                "metrics_file_path": str(self.training_metrics_file),
                "total_records": self.training_metrics.get("loss_records_count", 0),
                "training_duration_seconds": self.training_metrics.get("training_duration_seconds"),
                "best_train_loss": self.training_metrics.get("best_train_loss"),
                "best_eval_loss": self.training_metrics.get("best_eval_loss"),
                "total_steps": self.training_metrics.get("total_steps", 0),
                "epochs_completed": self.training_metrics.get("epochs_completed", 0),
                "start_time": self.training_metrics.get("start_time"),
                "end_time": self.training_metrics.get("end_time"),
                "status": self.training_metrics.get("status", "running"),
                "epoch_summaries": self.training_metrics.get("epoch_summaries", []),
                "final_metrics": self.training_metrics.get("final_metrics", {})
            }
            return summary
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ•°æ®åº“æ±‡æ€»ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def finalize_training(self, final_metrics: Optional[Dict[str, Any]] = None):
        """
        å®Œæˆè®­ç»ƒï¼Œä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        
        Args:
            final_metrics: æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡
        """
        with self.lock:
            try:
                # æ›´æ–°å®Œæˆæ—¶é—´
                self.training_metrics["end_time"] = datetime.now().isoformat()
                self.training_metrics["status"] = "completed"
                
                # æ·»åŠ æœ€ç»ˆæŒ‡æ ‡
                if final_metrics:
                    self.training_metrics["final_metrics"] = final_metrics
                
                # è®¡ç®—è®­ç»ƒæ—¶é•¿
                if "start_time" in self.training_metrics:
                    start_time = datetime.fromisoformat(self.training_metrics["start_time"])
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    self.training_metrics["training_duration_seconds"] = duration
                
                # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
                with open(self.training_metrics_file, 'w', encoding='utf-8') as f:
                    json.dump(self.training_metrics, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… è®­ç»ƒæŒ‡æ ‡å·²å®Œæˆä¿å­˜: {self.training_metrics_file}")
                
                # è¿”å›æ•°æ®åº“æ±‡æ€»ä¿¡æ¯ä¾›è°ƒç”¨è€…ä½¿ç”¨
                return self.get_database_summary()
                
            except Exception as e:
                logger.error(f"âŒ å®Œæˆè®­ç»ƒæŒ‡æ ‡ä¿å­˜å¤±è´¥: {e}")
                return None


# å…¨å±€lossç®¡ç†å™¨å®ä¾‹å­—å…¸ {task_id: LossManager}
_loss_managers: Dict[str, LossManager] = {}
_managers_lock = Lock()


def get_loss_manager(output_dir: str, task_id: str) -> LossManager:
    """è·å–æˆ–åˆ›å»ºlossç®¡ç†å™¨å®ä¾‹"""
    with _managers_lock:
        if task_id not in _loss_managers:
            _loss_managers[task_id] = LossManager(output_dir, task_id)
        return _loss_managers[task_id]


def cleanup_loss_manager(task_id: str, final_metrics: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
    """
    æ¸…ç†lossç®¡ç†å™¨å®ä¾‹
    
    Args:
        task_id: ä»»åŠ¡ID
        final_metrics: æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡
        
    Returns:
        æ•°æ®åº“æ±‡æ€»ä¿¡æ¯ï¼Œç”¨äºå­˜å‚¨åˆ°æ•°æ®åº“
    """
    with _managers_lock:
        if task_id in _loss_managers:
            try:
                # å®Œæˆè®­ç»ƒå¹¶è·å–æ±‡æ€»ä¿¡æ¯
                summary = _loss_managers[task_id].finalize_training(final_metrics)
                del _loss_managers[task_id]
                logger.info(f"ğŸ§¹ æ¸…ç†lossç®¡ç†å™¨: {task_id}")
                return summary
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†lossç®¡ç†å™¨å¤±è´¥: {e}")
                return None
        return None