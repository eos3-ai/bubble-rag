"""
æ ‡å‡†åŒ–è¯„ä¼°ç»“æœå¤„ç†

æä¾›ç»Ÿä¸€çš„è¯„ä¼°ç»“æœåŒ…è£…å’Œå¤„ç†åŠŸèƒ½
"""
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from .metric_registry import get_metric_registry, MetricRegistry

@dataclass
class EvaluationResult:
    """æ ‡å‡†åŒ–è¯„ä¼°ç»“æœ"""
    source_id: str                    # æ•°æ®æºID
    dataset_name: str                # æ•°æ®é›†åç§°
    evaluator_name: str              # è¯„ä¼°å™¨åç§°
    step: int                        # è®­ç»ƒæ­¥æ•°
    epoch: Optional[float] = None    # è®­ç»ƒè½®æ•°
    metrics: Dict[str, float] = None # è¯„ä¼°æŒ‡æ ‡
    metadata: Dict[str, Any] = None  # å…ƒæ•°æ®

    def __post_init__(self):
        if self.metrics is None:
            self.metrics = {}
        if self.metadata is None:
            self.metadata = {}

    def add_metric(self, name: str, value: float):
        """æ·»åŠ è¯„ä¼°æŒ‡æ ‡"""
        self.metrics[name] = value

    def get_standardized_metrics(self) -> Dict[str, float]:
        """è·å–æ ‡å‡†åŒ–çš„æŒ‡æ ‡åç§° (eval_{source_id}_{metric})"""
        standardized = {}
        for metric_name, value in self.metrics.items():
            standardized_name = f"eval_{self.source_id}_{metric_name}"
            standardized[standardized_name] = value
        return standardized

    def get_frontend_format(self, registry: MetricRegistry = None) -> Dict[str, Any]:
        """è·å–å‰ç«¯æ ¼å¼çš„æ•°æ®"""
        if registry is None:
            registry = get_metric_registry()

        # è·å–å…ƒæ•°æ®
        metric_names = list(self.metrics.keys())
        frontend_metadata = registry.get_frontend_metadata(metric_names)

        return {
            "step": self.step,
            "epoch": self.epoch,
            "source_id": self.source_id,
            "dataset_name": self.dataset_name,
            "evaluator_name": self.evaluator_name,
            "metrics": self.metrics,
            "standardized_metrics": self.get_standardized_metrics(),
            "metadata": {
                **self.metadata,
                **frontend_metadata
            }
        }

class EvaluationResultProcessor:
    """è¯„ä¼°ç»“æœå¤„ç†å™¨"""

    def __init__(self):
        self.registry = get_metric_registry()

    def extract_evaluation_results_from_logs(self, loss_data: List[Dict[str, Any]]) -> List[EvaluationResult]:
        """ä»lossæ—¥å¿—æ•°æ®ä¸­æå–è¯„ä¼°ç»“æœ"""
        results = []

        for record in loss_data:
            step = record.get('step', 0)
            epoch = record.get('epoch')

            # æŒ‰æ•°æ®æºåˆ†ç»„æŒ‡æ ‡
            source_metrics = self._group_metrics_by_source(record)

            for source_id, metrics in source_metrics.items():
                if metrics:  # åªå¤„ç†æœ‰æŒ‡æ ‡çš„æ•°æ®æº
                    # æ¨æ–­è¯„ä¼°å™¨ä¿¡æ¯
                    evaluator_name = self._infer_evaluator_name(metrics)

                    result = EvaluationResult(
                        source_id=source_id,
                        dataset_name=f"source_{source_id}",  # é»˜è®¤åç§°ï¼Œåç»­ä¼šè¢«æ˜ å°„
                        evaluator_name=evaluator_name,
                        step=step,
                        epoch=epoch,
                        metrics=metrics
                    )

                    results.append(result)

        return results

    def _group_metrics_by_source(self, record: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
        """æŒ‰æ•°æ®æºåˆ†ç»„æŒ‡æ ‡"""
        source_metrics = {}

        for key, value in record.items():
            if key.startswith('eval_') and isinstance(value, (int, float)):
                # è§£æ eval_{source_id}_{metric_name} æ ¼å¼
                parts = key[5:].split('_')  # å»æ‰ 'eval_' å‰ç¼€
                if len(parts) >= 2 and parts[0].isdigit():
                    source_id = parts[0]
                    metric_name = '_'.join(parts[1:])

                    if source_id not in source_metrics:
                        source_metrics[source_id] = {}

                    source_metrics[source_id][metric_name] = value

        return source_metrics

    def _infer_evaluator_name(self, metrics: Dict[str, float]) -> str:
        """ä»æŒ‡æ ‡æ¨æ–­è¯„ä¼°å™¨åç§°"""
        metric_names = list(metrics.keys())
        evaluator_type = self.registry.infer_evaluator_type_from_metrics(metric_names)

        if evaluator_type:
            # æŸ¥æ‰¾åŒ¹é…çš„è¯„ä¼°å™¨
            for evaluator_name, evaluator_info in self.registry.evaluators.items():
                if evaluator_info.evaluator_type == evaluator_type:
                    return evaluator_name

        return "UnknownEvaluator"

    def apply_dataset_mapping(self, results: List[EvaluationResult],
                            source_mapping: Dict[str, str]) -> List[EvaluationResult]:
        """åº”ç”¨æ•°æ®é›†åç§°æ˜ å°„"""
        for result in results:
            if result.source_id in source_mapping:
                result.dataset_name = source_mapping[result.source_id]

        return results

    def convert_to_frontend_format(self, results: List[EvaluationResult]) -> List[Dict[str, Any]]:
        """è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼"""
        return [result.get_frontend_format(self.registry) for result in results]

    def enhance_loss_data_with_metadata(self, loss_data: List[Dict[str, Any]],
                                      source_mapping: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """ä¸ºlossæ•°æ®å¢å¼ºå…ƒæ•°æ®"""
        enhanced_data = []

        for record in loss_data:
            enhanced_record = record.copy()

            # æå–è¯„ä¼°æŒ‡æ ‡
            eval_metrics = {}
            for key, value in record.items():
                if key.startswith('eval_') and isinstance(value, (int, float)):
                    eval_metrics[key] = value

            if eval_metrics:
                # è·å–å…ƒæ•°æ®
                metric_names = []
                for key in eval_metrics.keys():
                    # ä» eval_{source_id}_{metric_name} æå– metric_name
                    parts = key[5:].split('_')  # å»æ‰ 'eval_' å‰ç¼€
                    if len(parts) >= 2:
                        metric_name = '_'.join(parts[1:])
                        metric_names.append(metric_name)

                if metric_names:
                    frontend_metadata = self.registry.get_frontend_metadata(metric_names)
                    enhanced_record['evaluation_metadata'] = frontend_metadata

            enhanced_data.append(enhanced_record)

        return enhanced_data

# å…¨å±€å¤„ç†å™¨å®ä¾‹
evaluation_result_processor = EvaluationResultProcessor()

def get_evaluation_result_processor() -> EvaluationResultProcessor:
    """è·å–å…¨å±€è¯„ä¼°ç»“æœå¤„ç†å™¨"""
    return evaluation_result_processor

def save_evaluation_results_to_database(task_id: str, eval_results: Dict[str, Any], step: int, epoch: Optional[float] = None, data_source_mapping: Dict[str, str] = None):
    """ä¿å­˜è¯„ä¼°å™¨ç»“æœåˆ°æ•°æ®åº“"""
    try:
        from bubble_rag.training.mysql_service.service.training_dataset_service import TrainingDatasetService
        import logging
        logger = logging.getLogger(__name__)

        # æ­¥éª¤1: ç»Ÿä¸€æ ¼å¼è½¬æ¢ - å°†æ‰€æœ‰éæ ‡å‡†æ ¼å¼è½¬æ¢ä¸º eval_{source_id}_{metric} æ ¼å¼
        converted_results = _convert_all_to_standard_format(eval_results, data_source_mapping)
        logger.debug(f"æ ¼å¼è½¬æ¢å®Œæˆ: {list(converted_results.keys())}")

        # æ­¥éª¤2a: å…ˆå¤„ç†lossæ•°æ® - ä¿å­˜åˆ°losså­—æ®µ
        loss_results = {k: v for k, v in converted_results.items() if 'loss' in k.lower()}
        if loss_results:
            loss_source_results = _split_by_source_id(loss_results)
            eval_datasets = TrainingDatasetService.get_datasets_by_job_and_split(task_id, "eval")
            for source_id, source_loss_data in loss_source_results.items():
                matching_dataset = None
                for dataset in eval_datasets:
                    if dataset.get("data_source_id") == source_id:
                        matching_dataset = dataset
                        break

                if matching_dataset:
                    dataset_id = matching_dataset["id"]
                    for loss_key, loss_value in source_loss_data.items():
                        if 'loss' in loss_key.lower() and isinstance(loss_value, (int, float)):
                            TrainingDatasetService.add_loss_record(
                                dataset_id=dataset_id,
                                loss_value=loss_value,
                                step=step,
                                epoch=epoch
                            )
                            logger.debug(f"ğŸ’¾ æ•°æ®æº{source_id}çš„losså·²ä¿å­˜: dataset_id={dataset_id}, step={step}, {loss_key}={loss_value}")

        # æ­¥éª¤2b: ç­›é™¤loss - åªä¿ç•™élossçš„è¯„ä¼°æŒ‡æ ‡
        non_loss_results = {k: v for k, v in converted_results.items() if 'loss' not in k.lower()}
        logger.debug(f"ğŸ—‘ï¸ ç­›é™¤losså: {list(non_loss_results.keys())}")

        # æ­¥éª¤3: æŒ‰æ•°æ®æºåˆ†ç¦»
        source_eval_results = _split_by_source_id(non_loss_results)
        logger.debug(f"æŒ‰æ•°æ®æºåˆ†ç¦»: {list(source_eval_results.keys())}")

        # æ­¥éª¤4: ä¸ºæ¯ä¸ªæ•°æ®æºä¿å­˜è¯„ä¼°æŒ‡æ ‡åˆ°æ•°æ®åº“
        eval_datasets = TrainingDatasetService.get_datasets_by_job_and_split(task_id, "eval")
        for source_id, source_results in source_eval_results.items():
            matching_dataset = None
            for dataset in eval_datasets:
                if dataset.get("data_source_id") == source_id:
                    matching_dataset = dataset
                    break

            if matching_dataset:
                dataset_id = matching_dataset["id"]
                TrainingDatasetService.add_training_evaluator_evaluation(
                    dataset_id=dataset_id,
                    eval_results=source_results,
                    step=step,
                    epoch=epoch
                )
                logger.debug(f"ğŸ’¾ æ•°æ®æº{source_id}è¯„ä¼°ç»“æœå·²ä¿å­˜: dataset_id={dataset_id}, step={step}, metrics={list(source_results.keys())}")

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.warning(f"ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")

def _convert_all_to_standard_format(eval_results: Dict[str, Any], data_source_mapping: Dict[str, str] = None) -> Dict[str, Any]:
    """æ­¥éª¤1: å°†æ‰€æœ‰æŒ‡æ ‡è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    converted = {}

    # å¤„ç†æ•°æ®é›†åç§°æ˜ å°„
    dataset_to_source = {}
    if data_source_mapping:
        for full_name, source_id in data_source_mapping.items():
            if '/' in full_name:
                dataset_name = full_name.split('/')[-1]
                dataset_to_source[dataset_name] = source_id
            dataset_to_source[full_name] = source_id

    for key, value in eval_results.items():
        if key.startswith('eval_'):
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ eval_{æ•°å­—}_*
            remaining = key[5:]  # å»æ‰'eval_'
            parts = remaining.split('_')
            if len(parts) >= 2 and parts[0].isdigit():
                # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥ä¿ç•™
                converted[key] = value
            else:
                # éæ ‡å‡†æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                converted_key = None
                for dataset_name, source_id in dataset_to_source.items():
                    if dataset_name in key:
                        # æå–æŒ‡æ ‡å
                        dataset_pos = key.find(dataset_name)
                        metric_suffix = key[dataset_pos + len(dataset_name):]
                        if metric_suffix.startswith('_'):
                            metric_suffix = metric_suffix[1:]

                        converted_key = f"eval_{source_id}_{metric_suffix}"
                        break

                if converted_key:
                    converted[converted_key] = value
                else:
                    # æ— æ³•è½¬æ¢ï¼Œä¿æŒåŸæ ·ï¼ˆå¦‚ç»Ÿä¸€æŒ‡æ ‡ï¼‰
                    converted[key] = value
        else:
            # éevalå­—æ®µï¼Œç›´æ¥ä¿ç•™
            converted[key] = value

    return converted

def _split_by_source_id(eval_results: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """æ­¥éª¤3: æŒ‰æ•°æ®æºIDåˆ†ç¦»ï¼ˆæ‰€æœ‰æ•°æ®å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼‰"""
    source_results = {}
    unified_metrics = {}

    # æ”¶é›†æ‰€æœ‰source_id
    source_ids = set()
    for key in eval_results.keys():
        if key.startswith('eval_'):
            parts = key[5:].split('_')
            if len(parts) >= 2 and parts[0].isdigit():
                source_ids.add(parts[0])

    for key, value in eval_results.items():
        if key.startswith('eval_'):
            parts = key[5:].split('_')
            if len(parts) >= 2 and parts[0].isdigit():
                # æ ‡å‡†æ ¼å¼ï¼šåˆ†é…åˆ°å¯¹åº”æ•°æ®æº
                source_id = parts[0]
                if source_id not in source_results:
                    source_results[source_id] = {}
                source_results[source_id][key] = value
            else:
                # ç»Ÿä¸€æŒ‡æ ‡ï¼šæ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æº
                metric_name = key[5:]  # å»æ‰eval_å‰ç¼€
                unified_metrics[metric_name] = value
        else:
            # éevalå­—æ®µï¼ˆå¦‚epochï¼‰ï¼šæ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æº
            unified_metrics[key] = value

    # å°†ç»Ÿä¸€æŒ‡æ ‡æ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æº
    for source_id in source_results.keys():
        source_results[source_id].update(unified_metrics)

    return source_results

def _separate_eval_results_by_source(eval_results: Dict[str, Any], data_source_mapping: Dict[str, str] = None) -> Dict[str, Dict[str, Any]]:
    """æŒ‰æ•°æ®æºåˆ†ç¦»è¯„ä¼°ç»“æœ"""
    source_eval_results = {}

    # æ„å»ºæ•°æ®é›†åç§°åˆ°source_idçš„æ˜ å°„ï¼ˆé€šç”¨æ–¹æ³•ï¼Œå’Œæœ¬åœ°æ–‡ä»¶é€»è¾‘ä¸€è‡´ï¼‰
    dataset_to_source_mapping = {}
    if data_source_mapping:
        # ä»eval keysä¸­æå–æ•°æ®é›†åç§°
        eval_keys = [key for key in eval_results.keys() if key.startswith('eval_')]
        dataset_names = set()
        for key in eval_keys:
            # æå–å¯èƒ½çš„æ•°æ®é›†åç§°ï¼ˆå»æ‰eval_å‰ç¼€å’Œåé¢çš„metricï¼‰
            remaining = key[5:]  # å»æ‰'eval_'
            if not remaining.split('_')[0].isdigit():  # ä¸æ˜¯æ ‡å‡†æ ¼å¼
                # å¯èƒ½åŒ…å«æ•°æ®é›†åç§°ï¼Œå°è¯•æå–
                parts = remaining.split('_')
                for i in range(1, len(parts)):
                    potential_dataset = '_'.join(parts[:i])
                    dataset_names.add(potential_dataset)

        # å»ºç«‹æ˜ å°„å…³ç³»
        for dataset_name in dataset_names:
            for full_name, source_id in data_source_mapping.items():
                if dataset_name in full_name:
                    dataset_to_source_mapping[dataset_name] = source_id
                    break

    for key, value in eval_results.items():
        if key.startswith('eval_'):
            assigned_to_source = False
            remaining = key[5:]  # å»æ‰'eval_'

            # æ ¼å¼1: eval_{source_id}_{metric} (æ ‡å‡†æ ¼å¼)
            parts = remaining.split('_')
            if len(parts) >= 2 and parts[0].isdigit():
                source_id = parts[0]
                metric_name = '_'.join(parts[1:])
                if source_id not in source_eval_results:
                    source_eval_results[source_id] = {}
                source_eval_results[source_id][metric_name] = value
                assigned_to_source = True

            # æ ¼å¼2: å…¶ä»–æ ¼å¼ï¼Œé€šè¿‡datasetåç§°åŒ¹é…ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            elif not assigned_to_source and dataset_to_source_mapping:
                for dataset_name, source_id in dataset_to_source_mapping.items():
                    if dataset_name in key:
                        # æå–æŒ‡æ ‡åå¹¶è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                        # eval_sentence-transformers/stsb_runtime -> eval_2_runtime
                        remaining = key[5:]  # å»æ‰'eval_'
                        if dataset_name in remaining:
                            # æ‰¾åˆ°æ•°æ®é›†åç§°ä½ç½®ï¼Œæå–åé¢çš„æŒ‡æ ‡å
                            dataset_pos = remaining.find(dataset_name)
                            metric_suffix = remaining[dataset_pos + len(dataset_name):]
                            if metric_suffix.startswith('_'):
                                metric_suffix = metric_suffix[1:]  # å»æ‰å¼€å¤´çš„ä¸‹åˆ’çº¿

                            # ç”Ÿæˆæ ‡å‡†æ ¼å¼çš„key
                            standard_key = f"eval_{source_id}_{metric_suffix}"
                        else:
                            # å¤‡ç”¨æ–¹æ¡ˆ
                            metric_suffix = key.split('_')[-1]
                            standard_key = f"eval_{source_id}_{metric_suffix}"

                        if source_id not in source_eval_results:
                            source_eval_results[source_id] = {}
                        source_eval_results[source_id][standard_key] = value
                        assigned_to_source = True
                        break

    # å¤„ç†ç»Ÿä¸€æŒ‡æ ‡ï¼ˆå¦‚eval_sequential_scoreï¼‰ï¼Œæ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æºä¸­
    unified_metrics = {}
    for key, value in eval_results.items():
        if key.startswith('eval_'):
            assigned_to_any_source = False

            # æ£€æŸ¥æ˜¯å¦å·²è¢«åˆ†é…åˆ°æŸä¸ªæ•°æ®æº
            # 1. æ£€æŸ¥æ ‡å‡†æ ¼å¼ eval_{source_id}_*
            parts = key[5:].split('_')
            if len(parts) >= 2 and parts[0].isdigit() and parts[0] in source_eval_results:
                assigned_to_any_source = True

            # 2. æ£€æŸ¥éæ ‡å‡†æ ¼å¼ï¼ˆé€šè¿‡æ•°æ®é›†åç§°åŒ¹é…ï¼‰
            if not assigned_to_any_source and dataset_to_source_mapping:
                for dataset_name in dataset_to_source_mapping.keys():
                    if dataset_name in key:
                        assigned_to_any_source = True
                        break

            # å¦‚æœæ²¡æœ‰è¢«åˆ†é…åˆ°ä»»ä½•æ•°æ®æºï¼Œè®¤ä¸ºæ˜¯ç»Ÿä¸€æŒ‡æ ‡
            if not assigned_to_any_source:
                metric_name = key[5:]  # å»æ‰eval_å‰ç¼€
                unified_metrics[metric_name] = value

    # å¤„ç†éevalå­—æ®µï¼ˆå¦‚epochï¼‰ï¼Œæ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æºä¸­
    non_eval_fields = {}
    for key, value in eval_results.items():
        if not key.startswith('eval_'):
            non_eval_fields[key] = value

    # å°†ç»Ÿä¸€æŒ‡æ ‡å’Œéevalå­—æ®µæ·»åŠ åˆ°æ‰€æœ‰æ•°æ®æºä¸­
    for source_id in source_eval_results.keys():
        # æ·»åŠ ç»Ÿä¸€æŒ‡æ ‡
        for metric_name, metric_value in unified_metrics.items():
            source_eval_results[source_id][metric_name] = metric_value
        # æ·»åŠ éevalå­—æ®µï¼ˆå¦‚epochï¼‰
        for field_name, field_value in non_eval_fields.items():
            source_eval_results[source_id][field_name] = field_value

    return source_eval_results